\documentclass[twocolumn, aps, amsmath, amssymb, nofootinbib, superscriptaddress, longbibliography, doublefloatfix, table-of-contents, eqsecnum, rmp]{revtex4-2}

\usepackage[pdftex]{graphicx}
\usepackage{mathrsfs}
\usepackage[colorlinks, breaklinks, urlcolor={blue}, linkcolor={red}, citecolor={blue}]{hyperref}
\usepackage[english]{babel}
\usepackage{booktabs}
\usepackage{type1cm}
\usepackage{caption}
\usepackage{url}
\usepackage[breaklinks]{hyperref}
\usepackage{stmaryrd}
    
\frenchspacing
    
\captionsetup[figure]{margin=0pt, font=small, labelfont=bf, labelsep=endash, justification=centerlast, labelsep=colon}
\captionsetup[algorithm]{margin=0pt, font=small, labelfont=bf, labelsep=endash, justification=centerlast, labelsep=colon}
    
\def\sk{\mathtt{sk}}
\def\pk{\mathtt{pk}}
\def\kp{\mathtt{kp}}
\def\sig{\mathtt{sig}}
\def\ver{\mathtt{ver}}
\def\enc{\mathtt{enc}}
\def\dec{\mathtt{dec}}
\def\zerovec{\mathbf{0}}
\def\onevec{\mathbf{1}}
\def\diff#1#2{\llbracket #1,#2\rrbracket}
%\def\asym#1#2#3{\langle #1_#3 #2_{#3^{-1}}\rangle}
%\def\asymd#1#2#3#4{\langle #1_{#3} \cdot #2_{#4}\rangle}
\def\braid#1#2#3#4{\langle#1,#2\rangle_{#3}^{#4}}
\def\selfbraid#1#2#3{\langle#1\rangle_{#2}^{#3}}
\def\symbraid#1{\langle#1\rangle_{\pi}^{\pi^{-1}}}
\def\comm#1#2#3#4{[#1,#2]_{#3}^{#4}}

%\def\stackbraid#1#2{\genfrac[]{#1}{#2}_{\pi}^{\pi^{-1}}}
%\def\stackbraid#1#2{\langle\begin{subarray}{c}#1\\#2\end{subarray}\rangle_{\pi}^{\pi^{-1}}}
%\newcommand{\stackbraid}[2]{\genfrac{[}{]}{0pt}{}{$#1$}{$#2$}^{\pi^{-1}}_{\pi}}

\newcommand{\stackbraid}[2]{{\genfrac{[}{]}{0pt}{}{{#1}}{{#2}}}^{\bar{\pi}}_{\pi}}
\newcommand{\stackbraidpow}[3]{{\genfrac{[}{]}{0pt}{}{{#1}}{{#2}}}^{\bar{\pi}^{#3}}_{\pi^#3}}
\newcommand{\stackbraidgen}[4]{{\genfrac{[}{]}{0pt}{}{{#1}}{{#2}}}^{#3}_{#4}}

\makeatletter
\newcommand{\soplus}{{{\hspace{1pt}}{\mathbin{\mathpalette\make@small{\mathbin\oplus}}}}{\hspace{1pt}}}

\newcommand{\make@small}[2]{%
  \vcenter{\hbox{%
    \scalebox{0.6}{$\m@th#1#2$}%
  }}%
}
\makeatother

\begin{document}

\title{Information theoretically secure post-quantum cryptography}

\author{Peter P. Rohde}
\email[]{peter@peterrohde.org}
\homepage{https://www.peterrohde.org}

\begin{abstract}
\end{abstract}

\maketitle

\tableofcontents

\section{Links \& chats}

\begin{itemize}
	\item One way functions and P vs NP: \url{https://en.wikipedia.org/wiki/One-way_function}: "The existence of such one-way functions is still an open conjecture. Their existence would prove that the complexity classes P and NP are not equal,"\\
		* one-way permutation.\\
		* Trapdoor function.\\
	\item GapP, NP, binary optimisation problems: \url{https://chatgpt.com/share/2e9f8c0f-fa1d-4d97-9af0-c195ad3cd22c}
	\item Homomorphism between $B_n$ and $S_n$: \url{https://chatgpt.com/share/c0390897-77f1-403e-bce9-ca2bf5c9fccc}
	\item Even Hamming weight for $H(x\soplus y)\in 2\mathbb{Z}$ if $H(x)=H(y)$. Hence also for $y=\pi\circ x$ where $\pi\in S_n$.
	\item Word problem for the braid group $B_n$ is poly-time solvable: \url{https://chatgpt.com/c/f8827503-7af9-4b81-b3dd-a79f1891746e}
	\item Wreath product \url{https://en.wikipedia.org/wiki/Wreath_product}
	\item Braid permutations \mbox{$\pi: B_n \to S_n$}, for $\beta\in B_n$ we have $\pi(\beta)$: \url{https://chatgpt.com/share/6c61f5ef-a33d-4c76-8f1f-0d8bdf1bb4aa}
	\item Inverting braids $\stackbraid{x}{x}\to x$ is equivalent to the Conjugacy Problem for Permutations (CPP), known to be NP-complete. For braid codes complexity is maximised for the balanced pre-image space, $\mathrm{wt}(x)=n/2$.
\end{itemize}

\section{Overview}

The goal is to create information-theoretically secure asymmetric PQC primitives where the only hardness assumption is the hardness of brute-force, reducing all arguments to entropic ones.

There are multiple primitives we will combine together.

The purpose of differential encoding is create differential pairs encoded against a secret, where the differential term is public and cannot reveal the secret itself.

Combining differential encoding with random codewords we have a codespace where all codewords are unique (statistical security assumption) and errors on differentials are always detectable (but not correctable).

Permutation codes and their respective algebra are used to create asymmetric primitives from random codewords. This closely relates to and is inspired by hash algebra. Here the central concept is that any permutation on the bits in codewords creates a distinct codeword (statistical security assumption). The asymmetric objects introduced here are defines under the algebra of the symmetric group and their inversion assuming random codewords is only via brute force as the objects are provably non-invertible.

The security of asymmetric objects relates to their pre-image space which decomposes into collisional and non-collisional partitions. The former is insecure (ambiguous secrets) while the latter is secure. Quantifying the size of these respective spaces affords provable statements on statistical security alone.

The schemes resulting from this are compositional under binary XOR algebra.

\section{Braid code summary}

Asymmetric encryption ($A\to B: m$):
\begin{align}
%	\mathtt{ver}_A:\, &\stackbraid{h(m)}{m},\nonumber\\
	\mathtt{sig}_A:\, &\stackbraid{h(m\oplus p)}{m},\nonumber\\
	\mathtt{key}_B:\, &\stackbraid{s}{p},\nonumber\\
	\mathtt{dec}_B:\, &\stackbraid{h(m\oplus p)}{m}\oplus \stackbraid{s}{p} = \stackbraid{h(m\oplus p)\oplus s}{m\oplus p},
%	\mathtt{Decrypt}:\, &\stackbraid{h(m)}{m}\oplus \stackbraid{s}{p} = \stackbraid{h(m)\oplus s}{m\oplus p},\nonumber\\
%		&\stackbraid{h(m)\oplus s}{m\oplus p} \oplus \stackbraid{h(m)\oplus s}{p} \nonumber\\
%		&= m_\pi \xrightarrow{\pi^{-1}} m,
\end{align}
where knowledge of $\{s,p,h(m),\pi\}$ affords the decryption stage.

Digital signature for $m$:
\begin{align}
%	\mathtt{pk}_A:\, &\stackbraid{s}{p},\nonumber\\
%	\mathtt{ver}_A:\, &\stackbraid{m}{h(m\oplus p)},\nonumber\\
	\mathtt{sig}_A:\, &h(m \oplus p),\nonumber\\
	\mathtt{key}_B:\, &\stackbraid{s}{p},\nonumber\\
	\mathtt{dec}_B:\, &\stackbraid{m}{h(m)}\oplus \stackbraid{s}{p} = \stackbraid{m\oplus s}{h(m)\oplus p}.
\end{align}

%Key agreement (shared randomness):
%* Perform \texttt{enc} in both directions.
%* Both sides have $\{m_A,m_B,h(m_A),h(m_B)\}$.
%* 
%* Mutual confirmation via $h(m_A\oplus m_B)$.

%
%\begin{align}
%	\mathtt{Alice,Bob}:\, &\stackbraid{h(m_{A,B})}{m_{A,B}},\nonumber\\
%	\mathtt{Alice,Bob}:\, &\stackbraid{s_{A,B}}{p_{A,B}},\nonumber\\
%	\mathtt{Alice,Bob}:\, &m_A,m_B,\nonumber\\
%%	\mathtt{One-way verify}:\, &\stackbraid{h(m)}{m}\oplus \stackbraid{p}{s} = \stackbraid{h(m)\oplus p}{m\oplus s},\nonumber\\
%%		&\stackbraid{h(m)\oplus p}{m\oplus s} \oplus [m\oplus p]_{\pi^{-1}} \oplus s_\pi\nonumber\\
%%		&= h(m)_\pi \to h(m).
%	\mathtt{Confirm}: h(m_A\oplus m_B).
%\end{align}

\section{Entropy algebra}

The binary group, the abelian group of length $n$ bit-strings under bit-wise XOR\footnote{Elementary abelian 2-group.},
\begin{align}
	G_\mathrm{B} &= (\mathbb{Z}_2^n,\oplus) \sim  (\{0,1\}^n,\oplus),
\end{align}
we consider subgroups generated by finite alphabets of $k$ randomly sampled letters,
\begin{align}
	\mathcal{X}:\, &\Sigma \in \mathbb{Z}_2^n,\nonumber\\ %\{g_{i\in\{1,k\}} \in \{0,1\}^n\},\nonumber\\
	G_\Sigma &= \langle \Sigma \rangle, \nonumber\\
	G_\Sigma &\subseteq G_\mathrm{B},
\end{align}
where individual generators compose under $(\mathbb{Z}_2,\oplus)$,
\begin{align}
	g_i\oplus g_i = e \sim \zerovec,
\end{align}
and the identity element is the zero vector. Entropy groups have group generators representing independent random variables,
\begin{align}
	G_E &= \langle \mathcal{X}_{i\in\{1,k\}} \rangle \sim \mathbb{Z}_2^k,\nonumber\\
	|G_\mathrm{E}| &= 2^k,
\end{align}
where group elements comprise all binary combinations of group generators.

Independent maximum entropy letters,
\begin{align}
	H(\mathcal{X}) = 1,
\end{align}
exhibit no mutual information,
\begin{align}
	I(\mathcal{X}_i,\mathcal{X}_j) = \delta_{i,j},
\end{align}
and are statistically orthogonal, thereby constituting distinct letters in the algebra. Zero-entropy letters reduce to constants,
\begin{align}
	H(\mathcal{X} \to c) = 0.
\end{align}

Information theoretically, for maximum entropy random variables the entropy group generators are distinct,
\begin{align}
	G_\mathrm{ent} &= \langle \mathcal{X}_i,\mathcal{X}_j\rangle,\nonumber\\
	&= \{e,\mathcal{X}_i,\mathcal{X}_j, \mathcal{X}_i\soplus \mathcal{X}_j\} \nonumber\\
	&= \langle \mathcal{X}_i\rangle \times \langle \mathcal{X}_j\rangle \nonumber\\
	&\sim \mathbb{Z}_2 \times \mathbb{Z}_2.
\end{align}
Zero-entropy random variables have no information-theoretic content, reducing the action of the entropy group to the trivial group,
\begin{align}
	\phi:&\, \mathcal{X} \to e,\nonumber\\
	{\tilde{G}}_\mathrm{E} &= \{e\} \sim \mathbf{1}.
\end{align}
defining a group homomorphism mapping entropic code groups to non-entropic ones,
\begin{align}
	&\phi: G_\mathrm{C} \to {\tilde G}_\mathrm{C},\nonumber\\
	&\mathrm{ker}({\tilde G}_\mathrm{C}) = G_\mathrm{E},\nonumber\\
	&{\tilde G}_\mathrm{C} = G_\mathrm{C} \,/\, \mathrm{ker}(\phi) = G_\mathrm{C} / G_\mathrm{E}.
\end{align}

Code groups may contain both entropic ($\mathcal{X}$) and non-entropic generators ($x$) and group elements in general comprise letters from both ($\mathcal{X}\soplus x$). Non-entropic group elements comprising only non-entropic generators expose the group generators comprising the group element ($x$), whereas entropic elements ($\mathcal{X}\soplus x$) do not. The entropic and non-entropic subgroups partition a group into a direct product (sum under $\oplus$) decomposition,
\begin{align}
	G = G_\mathcal{X} \times \tilde{G}_\mathcal{X},
\end{align}
where the entropic subgroup $G_\mathcal{X}$ is protected while the non-entropic group is exposed.

Different parties in a multi-party communications protocol in general possess different generating sets defining their subjective code groups. In the context of an encryption protocol the goal is for communicating parties to establish private code groups exposing encrypted data, while ensuring the public code group exposes only entropic objects.

\subsection{Symmetric encryption}

Consider an entropy code group comprising two random variables ($\mathcal{X}_i,\mathcal{X}_j$), secrets ($s,p$), and message $m$, defining the group generators,
\begin{align}
	G_\mathrm{C} &= \langle s,p,m,\mathcal{X}_i,\mathcal{X}_j \rangle \sim \mathbb{Z}_2^5.
%	&= \{s,p,m,s\soplus p, s\soplus m, p\soplus m, s\soplus p\soplus m,\nonumber\\
%	&\quad \mathcal{X}_i, \mathcal{X}_j, \mathcal{X}_i\soplus \mathcal{X}_j\nonumber\\
%	&\quad s\soplus \mathcal{X}_i, s\soplus \mathcal{X}_j, \mathcal{X}_i \soplus \mathcal{X}_j,... \}
\end{align}
with $|G_\mathrm{C}|=2^5$ code words.

Assume Alice and Bob share secrets $\{s,p\}$. Let Alice prepare two random variables $\{\mathcal{X}_i,\mathcal{X}_j\}$ and message $m$. She publicly shares with Bob,
\begin{align}
	A\to B:\quad &\mathtt{pub} = \{s\soplus \mathcal{X}_i, \mathcal{X}_i \soplus \mathcal{X}_j, p \soplus m\soplus\mathcal{X}_j\}.
%\nonumber\\
%	G_\mathrm{pub}^{(1)} &= \langle S_\mathrm{pub}^{(1)} \rangle \nonumber\\
%	&= \{s\soplus \mathcal{X}_i, s\soplus \mathcal{X}_j, \mathcal{X}_i \soplus \mathcal{X}_j \}
\end{align}
The group generated by these objects does not reveal any non-entropic group elements. The group generated by public information is,
\begin{align}
	G_\mathrm{pub} &= \langle s\soplus \mathcal{X}_i, \mathcal{X}_i \soplus \mathcal{X}_j, p \soplus m\soplus\mathcal{X}_j\rangle,\nonumber\\
	&= \{s\soplus \mathcal{X}_i, s\soplus \mathcal{X}_j, \mathcal{X}_i \soplus \mathcal{X}_j,\nonumber\\
	&\quad p \soplus m\soplus\mathcal{X}_i, p \soplus m\soplus\mathcal{X}_j, \nonumber\\
	&\quad s\soplus p \soplus m\soplus\mathcal{X}_i, s\soplus p \soplus m\soplus\mathcal{X}_j\},
\end{align}
while the group defined over private group generators comprises the full generating set of the code group,
\begin{align}
	G_\mathrm{priv} = G_\mathrm{enc}.
\end{align}

%\begin{align}
%	S_\mathrm{priv} &= S_\mathrm{pub} \cup \{s,p\}\nonumber\\
%	&= \{s, \mathcal{X}_i, \mathcal{X}_i \soplus \mathcal{X}_j, p \soplus m\soplus\mathcal{X}_j\},\nonumber\\
%	G_\mathrm{priv} &= \langle S_\mathrm{priv} \rangle \nonumber\\
%	&= \{s\soplus \mathcal{X}_i, s\soplus \mathcal{X}_j, \mathcal{X}_i \soplus \mathcal{X}_j,\nonumber\\
%	&\quad p \soplus m\soplus\mathcal{X}_i, p \soplus m\soplus\mathcal{X}_j, \nonumber\\
%	&\quad s\soplus p \soplus m\soplus\mathcal{X}_i, s\soplus p \soplus m\soplus\mathcal{X}_j\},
%\end{align}

%* All group elements represent bit-strings inheriting $\mathtt{Z}_2$ (i.e XOR) algebra.

The set of a group's elements corresponds to the space of available information objects. Group elements containing random variables are themselves random variables. The group element,
\begin{align}
	g = x\soplus \mathcal{X},
\end{align}
has entropy,
\begin{align}
	H(g) \geq \max[H(x), H(\mathcal{X})],
\end{align}
for arbitrary $x$, and for $H(\mathcal{X})=1$ the object $g$ is a maximum entropy random variable revealing no information about $x$,
\begin{align}
	I(x,g) \leq 1-H(\mathcal{X}),
\end{align}
where $I(x,g)$ is measured per-bit. In the zero-entropy regime,
\begin{align}
	H(\mathcal{X}) = 0,
\end{align}
we have,
\begin{align}
	x\soplus \mathcal{X} \to x\soplus c,
\end{align}	
for constant $c$ under which variable $x$ is information-theoretically invariant with perfect mutual information,
\begin{align}
	I(x,g) = H(x).
\end{align}

%* The entropy group is generated by,
%\begin{align}
%	S_\mathrm{ent} &= \{\mathcal{X}_i,\mathcal{X}_j\}
%\end{align}

The respective zero-entropy private and public groups are,
\begin{align}
	{\tilde S}_\mathrm{priv} &= \{s, p, p \soplus m\},\nonumber\\
	{\tilde G}_\mathrm{priv} &= \langle {\tilde S}_\mathrm{priv} \rangle \nonumber\\
	&= \{s, p, m, s\soplus p, s\soplus m, p\soplus m, s\soplus p\soplus m\},\nonumber\\
	{\tilde S}_\mathrm{pub} &= \{s, p \soplus m\},\nonumber\\
	{\tilde G}_\mathrm{pub} &= \langle {\tilde S}_\mathrm{pub} \rangle \nonumber\\
	&= \{s, p\soplus m, s\soplus p\soplus m\}.
\end{align}
The zero-entropy public group contains group element $g=p\soplus m$. As $s$ and $p$ are reusable and static they exhibit no entropy,
\begin{align}
	H(\mathcal{X}_s)=H(\mathcal{X}_p)=0,	
\end{align}
and the non-entropic group homomorphism reveals the message,
\begin{align}
	\phi:\, \tilde{G}_\mathrm{pub} \to \langle m\rangle.
\end{align}

Equivalently, treating private key $p$ as a random variable, $g=m\soplus \mathcal{X}_p$ takes the form of a one-time-pad cipher. If $p$ is an infinite maximum entropy stream we have,
\begin{align}
	H(\mathcal{X}_p) &= 1,\nonumber\\
	H(m\soplus \mathcal{X}_p) &= 1.
\end{align}
For reused $p$ we have,
\begin{align}
	&H(\mathcal{X}_p) = 0,\nonumber\\
	&\phi: \,g\to m.
\end{align}

In the zero-entropy case the scheme reduces to a one-time-pad with reused private key, revealing as plaintext message parities,
\begin{align}
	(p\soplus m_1) \soplus (p \soplus m_2) = m_1 \soplus m_2.
\end{align}
With increasing messages or a single chosen plaintext this affords decorrelation of private information. Only when $p$ is chosen independently for every $m$ do we achieve information theoretic security.

%In the maximum entropy case all public group elements are maximum entropy states.

Conceptually, the scheme uses $\{s,p\}$ to prove parity constraints against other variables with a hidden parity constraint necessary to complete the proof. Against maximum entropy random variables parity proofs act as zero-knowledge proofs (ZKPs) and $\{s,p\}$ are reusable without information leakage so long as they remain statistically distinguishable. Proofs against known variables have no hidden parity revealing the solution.

The secret sharing of entropy achieved by quantum key distribution (QKD) is via the hidden parity constraint imposed by shared entanglement, enforcing measurement correlations in random outcomes. Entropy derives from Heisenberg uncertainty while entanglement-enforced hidden parity ensures mutual outcome. Here entropy is derived client side with hidden parity constraints imposed by the group algebra.

Notes:

* Probability of letter collisions exhibits birthday scaling,
\begin{align}
	P_\mathrm{C} &= O(k^2 2^{-n}).
\end{align}
Ensuring $P_\mathrm{C}< \delta$ requires space overhead,
\begin{align}
	n = O(\log(k^2/\delta)).
\end{align}

* Initial round requires two random variables. Subsequent rounds require only one additional random variable per block,  sliding against the previous one. The parity constraint is differentially encoded against the parity between $s$ and $p$, creating a perpetually evolving parity constraint. The first random variable can be interpreted as a key exchange round, followed encryption rounds. Hence the protocol has a fixed 2-fold multiplicative communications overhead with an extra one-off overhead during initial the key exchange round.

* Described above is unidirectional entropy exchange where security is bounded by the entropy of the sender. Performing the protocol in both directions and utilising their joint entropy under XOR ensures at least the entropy of either party, affording a communications channel with security satisfying both. The entropy group remains closed under multiple rounds and the additional group generators do violate the security of the group.

* This can be generalised to arbitrary numbers of parties over a fully connected network with $O(n^2)$ independent two-way exchanges. This enables multi-party key agreement, where the collective serves as its own entropy oracle.

* From a multi-party entropy exchange every subset of the entropic group generators forms its own secure entropic subgroup reflecting the respective complete subgraph. Every entropic subgroup is secure against all others.

\subsection{Universal homomorphic computing}

For an $m$-bit computation we entropically encode each bit with a unique random variable where the entropic generators are secret,
\begin{align}
	\bar{G}_\mathcal{X} &= \langle b_i \rangle_{i\in\{1,m\}},\nonumber\\
	G_\mathcal{X} &= \langle \mathcal{X}_i \soplus b_i \rangle_{i\in\{1,m\}}.
\end{align}
The respective group elements from both subgroups forming the computational subgroup form an injective group homomorphism under the information-theoretic action $\phi:\, \mathcal{X}\to c$,
\begin{align}
	\phi:\, G_\mathcal{X}  \hookrightarrow \bar{G}_\mathcal{X}.
\end{align}

A universal gate set may be implemented via the NOT and CNOT (reversible XOR) gates,
\begin{align}
	\mathrm{NOT}_i:&\, b_i \to \bar{b}_i \equiv b_i \to b_i\soplus \onevec,\\
	\phi:&\, \mathcal{X}_i\soplus b_i \to \mathcal{X}_i\soplus b_i \soplus \onevec,\nonumber\\
	\nonumber\\
	\mathrm{CNOT}_{i,j}:&\, (b_i,b_j) \to (b_i\soplus b_j,b_j),\nonumber\\
	\phi:\, &(s\soplus \mathcal{X}_i\soplus b_i, p\soplus \mathcal{X}_j\soplus b_j)\nonumber\\
	\to\, &(s\soplus p \soplus \mathcal{X}_i \soplus \mathcal{X}_j \soplus b_i \soplus b_j, p\soplus \mathcal{X}_j\soplus b_j),\nonumber
\end{align}
with public,
\begin{align}
	\mathtt{pub}:\,\{s\soplus \mathcal{X}_j\},
\end{align}
allowing the delegate to perform the $(p\soplus\mathcal{X}_i,\zerovec)$ correction to obtain,
\begin{align}
	(\mathcal{X}_i\soplus\mathcal{X}_j,\zerovec) \times (s\soplus \mathcal{X}_i\soplus b_i, s\soplus \mathcal{X}_j\soplus b_j) \to 
\end{align}

* FIX THIS. Use conjugate parity differentials.

* Use dual-rail complementary logical encoding, $b\to (b,\bar{b})$. This preserves parity under exchange $(\bar{b},b)$ or joint complement $(a,b)\to(\bar{a},\bar{b})$ operations.

* Construct a CNOT over a four-bit (2 dual-rail) space which is parity preserving under logical operations, thereby revealing no parity correlations.

* Define logical operations over of parity preserving primitives.

* Client provides server with matrix of entropy correlations with coefficients $M_{i,j} = \mathcal{X}_i\soplus \mathcal{X}_j$. These operators act as swaps when acting on entropic group generators, $(\mathcal{X}_i\soplus \mathcal{X}_j) \soplus \mathcal{X}_i = \mathcal{X}_j$, but do not reveal the generators themselves, preserving closure of protected subgroups.

* Turn homomorphic scheme into blind computing scheme by encoding logical operators under hidden parity constraints.

* Scheme has constant 2-fold multiplicative overhead (space and computational) associated with dual-rail encoding.

* Model: Arbitrary number of bits and a single CNOT acting on fixed bits. Permutation matrices reroute bits to the CNOT to enable universality. Permutation matrices are hidden in the entropy correlation matrix, \mbox{$M'=P\cdot M \cdot P^{-1}$}. Choose the $M'$ matrix to refresh entropic variables so that reuse does not reveal routing information. This has $O(m^2 d)$ overhead for an $m$-bit circuit with depth $d$.

\subsection{Non-abelian entropy injection}

Entropy injection from source $\tilde{\mathcal{X}}$ into $\mathcal{X}$ implemented via,
\begin{align}
	\mathcal{X}_{i+1} = \stackbraid{\mathcal{\tilde X}_{i+1}}{\tilde{\mathcal{X}_{i+1}}} \oplus \mathcal{X}_i.
\end{align}
has entropy,
\begin{align}
	H(\mathcal{X}_{i+1}) \geq \max[H(\mathcal{X}_i),H(\tilde{\mathcal{X}}_i)],
\end{align}
and is a non-abelian primitive under the assumption of the pre-image resistance of random braids. This prevents compromised sources from choosing,
\begin{align}
	\tilde{\mathcal{X}}_{i+1}=\mathcal{X}_i,
\end{align}
and eliminating entropy,
\begin{align}
	\mathcal{X}_{i+1} = \zerovec,
\end{align}
enabling cryptographically secure entropy addition.

\section{Hash algebra}

\subsection{Differential hash codes}

A pair of bit-strings $x,y\in\{0,1\}^n$ may be expressed differentially using the tuple,
\begin{align}
	[x,x\soplus y]_\soplus,
\end{align}
where the differential term $x\soplus y$ alone reveals no information about $x$ or $y$ while the non-differential term unlocks the code to reveal both. The validity of differentially encoded tuples may be trivially confirmed given knowledge of both terms.

We define the differential hash operators,
\begin{align}
	\Delta(x) &= h(x)\soplus x,\nonumber\\
	\Delta_\pi(x) &= h(x_\pi)\soplus x,
\end{align}
where $\pi\in S_n$ for $x\in\{0,1\}^n$ is a permutation over the elements of $x$. These encode a hash's image and pre-image together while revealing neither assuming hash pre-image resistance. We have the properties,
\begin{align}
	h(x) &= \Delta(x) \soplus x,\nonumber\\
	x &= \Delta(x) \soplus h(x).
\end{align}
The $\Delta$ operator inherits pre-image resistance from $h(\cdot)$. Knowing $\Delta(x)$ alone reveals neither $x$ nor $h(x)$, however additionally knowing $x$ or $h(x)$ enables verification of $\Delta(x)$. Finding $x$ for given $\Delta(x)$ reduces to the pre-image resistance of the hash function $h(\cdot)$.

The non-differentially encoded tuple $\{x,h(x)\}$ allows $x$ to unlock $h(x)$, while $h(x)$ cannot unlock $x$. The second element reveals $h(x)$ alone, but not $x$ via pre-image resistance. Under the differential encoding,
\begin{align}
	[x,\Delta(x)]_\soplus =[x,h(x)\soplus x]_\soplus,
\end{align}
the second element reveals neither $x$ nor $h(x)$, while the first element reveals both, given that $h(x)$ can be efficiently forward-evaluated. Alternately, under the differential encoding,
\begin{align}
	[h(x),\Delta(x)] = [h(x),h(x)\soplus x],
\end{align}
the non-differential term $h(x)$ affords unlocking the code but does not on its own reveal $x$ via hash pre-image resistance. Under both encodings knowing either $x$ or $h(x)$ alone enables verification.

The differential operator is distributive only over its unhashed components,
\begin{align}
	\Delta(x\soplus y) &= h(x\soplus y)\soplus x\soplus y \nonumber\\
	\Delta(x)\soplus\Delta(y) &= h(x)\soplus h(y)\soplus x\soplus y.
\end{align}
%Thus knowing $h(x\soplus y)$ does not unlock the object, whereas knowing both $x$ and $y$ does.

%Tuples of the form,
%\begin{align}
%	D(x,h(x)) &= [x, \Delta(x)], \nonumber\\
%	D(h(x),x) &= [h(x), \Delta(x)],
%\end{align}
%provide alternate differential encodings for $\{x,h(x)\}$, both affording efficient verification. A convenience is to collect terms known to different parties over the two sides of the encoding. Under both encodings knowing either $x$ or $h(x)$ unlocks both.

% We will generally treat the differential term as public and the non-differential term as private information.

%Taking bit-permuted tuples of this form, hash verification only succeeds if the correct inverse permutation is first applied.

%\subsection{Algebraic properties}

The symmetric difference between $\Delta(x\soplus y)$ and $\Delta(x)\soplus\Delta(y)$ gives the `distributor' (equivalent of commutator for distributivity),
\begin{align}
	\Delta(x\soplus y)\soplus \Delta(x)\soplus \Delta(y) = h(x\soplus y) \soplus h(x)\soplus h(y),
\end{align}
defining the distributivity of $\Delta$ operator over the action of $\soplus$.

Standard differential codes are composable,
\begin{align}
	[x,x\soplus y)]_\soplus \soplus [x',x'\soplus y']_\soplus\nonumber\\
	\sim [x\soplus x', x\soplus y \soplus x' \soplus y']_\soplus.
\end{align}
For differential hash codes,
\begin{align}
	[x,\Delta(x)]_\soplus,\nonumber\\
	[y,\Delta(y)]_\soplus,
\end{align}
we have distinct composition rules,
\begin{align}
	[x\soplus y,\Delta(x\soplus y)]_H,\nonumber\\
	[x\soplus y,\Delta(x) \soplus \Delta(y))]_\soplus.
\end{align}
The $[\cdot,\cdot]_H$ composition is verifiable by hashing the left hand term. The $[\cdot,\cdot]_\soplus$ composition is not hash-verifiable but preserves all differential encoding constraints.

Permutations $\pi$ are distributive over $\soplus$ but not commutative,
\begin{align}
	\pi(x\soplus y) &= \pi(x) \soplus \pi(y),\nonumber\\
	\pi(x) \soplus y &\neq x \soplus \pi(y),
\end{align}
whereas $\soplus$ is commutative but not distributive (in general, depending on parity of number of terms under distribution),
\begin{align}
	x\soplus y &= y \soplus x.
\end{align}

\begin{itemize}
	\item $h(m\soplus s)$ will reveal the private $h(s)$ for chosen $m=\mathbf{0}$.
	\item $h(m\soplus s \soplus x)$ will reveal the private $h(x)$ for chosen $m=x$ if $x$ is public.
	\item $h(\pi(m\soplus s)) = h(m_\pi \soplus s_\pi)$ can only reveal $h(s_\pi)$ (not secret) for public $\pi$ and chosen $m$, but cannot reveal secret $h(s)$.
\end{itemize}

\section{Braid code identities}

Following from the binary identities,
\begin{align}
	\bar{x} &= x \oplus \onevec,\nonumber\\
	\overline{x\oplus y} &= x \oplus \bar{y} = \bar{x} \oplus y.
\end{align}

\begin{align}
	\Delta_\pi(x) &\equiv \stackbraid{x}{x},\nonumber\\
	[\Delta_\pi \circ\Delta_\pi](x) &= [x_\pi \cdot x_{\pi^{-1}}]_\pi \cdot [x_\pi \cdot x_{\pi^{-1}}]_{\pi^{-1}} \nonumber\\
	&= x_{\pi^{2}} \cdot x \cdot x \cdot x_{\pi^{-2}} \nonumber\\
	&= x_{\pi^{2}} \cdot x_{\pi^{-2}} \nonumber\\
	&= \stackbraidpow{x}{x}{2},
\end{align}
where $x_\pi \equiv \pi \circ x$ and $\bar{\pi}\equiv \pi^{-1}$.

Braid flip:
\begin{align}
	\stackbraid{x}{y} \oplus \stackbraid{y}{x} &= \stackbraid{x}{x} \oplus \stackbraid{y}{y}.
\end{align}

Braid complement:
\begin{align}
	\overline{\stackbraid{x}{y}} &= \stackbraid{\bar{x}}{y} = \stackbraid{x}{\bar{y}} \nonumber\\
\stackbraid{x}{y} \oplus \stackbraid{\onevec}{\zerovec} &= \stackbraid{x}{y} \oplus \stackbraid{\zerovec}{\onevec}.
\end{align}

Braid group:
\begin{align}
	e &= \stackbraid{\zerovec}{\zerovec} = \stackbraid{\onevec}{\onevec},\nonumber\\
	g^{-1} &= \bar{g} = g\circ \stackbraid{\onevec}{\zerovec} = g\circ \stackbraid{\zerovec}{\onevec}.
\end{align}

Braid unlocking:
\begin{align}
	\stackbraid{x}{y} \oplus x_{\pi^{-1}} &= y_\pi,\nonumber\\
	\stackbraid{x}{y} \oplus y_{\pi} &= x_{\pi^{-1}}.
\end{align}

Braid permutations:
\begin{align}
	\pi \circ \stackbraid{x}{y} = \stackbraidgen{x}{y}{e}{\pi^2}.
\end{align}

Rebraiding:
\begin{align}
	\Delta_\pi \circ \stackbraid{x}{y} = \stackbraidpow{x}{y}{2}
\end{align}

Parity exchange:
\begin{align}
	\stackbraid{x}{x} &= \stackbraid{y}{y} \oplus [x\oplus y]_\pi,\nonumber\\
	\stackbraid{y}{y} &= \stackbraid{x}{x} \oplus [x\oplus y]^{\pi^{-1}}.
\end{align}

Braid-parity group:
\begin{align}
	G &= \left\langle s\oplus p, \stackbraid{s}{p} \right\rangle,\nonumber\\
	&= \{e, s\oplus p, \stackbraid{s}{s} \oplus \stackbraid{p}{p},\nonumber\\
	&\quad \stackbraid{s}{p}, \stackbraid{p}{s}, \stackbraid{s}{s}, \stackbraid{p}{p} \}.
\end{align}
Closed under the ring operations.

* What algebra is this? \url{https://en.wikipedia.org/wiki/Quaternion}

Reduction to permutations:
\begin{align}
	\stackbraid{\zerovec}{x} &= \pi \circ x,\nonumber\\
	\stackbraid{x}{\zerovec} &= \pi \circ \bar{x}.
\end{align}

\newpage

\section{Too much junk -- someone take out the trash}

\section{Differential encoding}

A pair of bit-strings $\{x,y\}\in\{0,1\}^n$ may be expressed differentially using the tuple,
\begin{align}
	\diff{x}{y} &\equiv [x,x\soplus y] \nonumber\\
	&\equiv [x\soplus y,x].
\end{align}
Here the differential term $x\soplus y$ alone reveals no information about $x$ or $y$ while the non-differential term unlocks the code to reveal both. The validity of differentially encoded tuples may be trivially confirmed given knowledge of both terms.

Differential encodings are composable under $\soplus$,
\begin{align}
	\diff{x_1}{y_1} \soplus \diff{x_2}{y_2} \Rightarrow \diff{x_1\soplus x_2}{y_1 \soplus y_2},
\end{align}
with the properties,
\begin{align}
	\diff{\zerovec}{x\soplus y} &= \diff{x}{y}, \nonumber\\
	\diff{x}{y} &\Rightarrow x=y.
\end{align}

\subsection{New stuff}

Use the convention of differentially encoded private and public information,
\begin{align}
	\Delta_i^{(k)} = [\mathtt{priv}_i^{(k)},\mathtt{pub}_i]_i,
\end{align}
where $i$ indexes an encoding and $k$ denotes an individual private party. Given a set of $\{\Delta_i\}_i$,
\begin{align}
	g_\mathtt{priv}^{(k)} &= \bigcup_i \mathtt{priv}_i^{(k)} \cup \mathtt{pub}_i,\nonumber\\
	g_\mathrm{pub} &=  \bigcup_i \mathtt{pub}_i
\end{align}
are the publicly and privately available objects, acting as group generators for the available algebra of operations under XOR,
\begin{align}
	G_\mathrm{priv}^{(k)} &\sim \langle g_\mathtt{priv}^{(k)} \rangle, \nonumber\\
	G_\mathrm{pub} &\sim \langle g_\mathtt{pub} \rangle,
\end{align}
where the public group is a subgroup of the private group,
\begin{align}
	G_\mathrm{pub} \subseteq G_\mathrm{priv}^{(k)}.
\end{align}

\subsubsection{Differential random codes}

Round of entropy exchange
\begin{align}
	A\to B:\quad &[s, s\soplus \mathcal{X}_i^A], \nonumber\\
	B\to A:\quad &[s, s\soplus \mathcal{X}_i^B],
\end{align}
yields the public information under addition,
\begin{align}
	A,B,\mathtt{pub}:\quad &[\zerovec, \mathcal{X}_i^A \soplus \mathcal{X}_i^B].
\end{align}
Hence the private and public group generators and elements are given by,
\begin{align}
	g_\mathtt{priv}^{A,B} &= \langle s, \mathcal{X}_i^A, \mathcal{X}_i^B \rangle,\nonumber\\
	&= \{\zerovec, s, \mathcal{X}_i^A, \mathcal{X}_i^B, s\soplus \mathcal{X}_i^A, s\soplus \mathcal{X}_i^B, \mathcal{X}_i^A \soplus \mathcal{X}_i^B, s\soplus \mathcal{X}_i^A \soplus \mathcal{X}_i^B \},\nonumber\\
	&= \mathrm{GF}(2^3), \nonumber\\
	g_\mathtt{pub} &= \langle s\soplus \mathcal{X}_i^A, s\soplus \mathcal{X}_i^B \rangle \nonumber\\
	&= \{\zerovec, s\soplus \mathcal{X}_i^A, s\soplus \mathcal{X}_i^B, \mathcal{X}_i^A \soplus \mathcal{X}_i^B \}, \nonumber\\
	&= \mathrm{GF}(2^2),
\end{align}
which factors into,
\begin{align}
	G_\mathtt{priv} = G_\mathtt{pub} \times \langle s\rangle,
\end{align}
where the private group is the subgroup of the public group invariant under $s$.

The above implements agreement upon the publicly known shared entropy source where,
\begin{align}
	\tilde{\mathcal{X}}_i &= \mathcal{X}_i^A \soplus \mathcal{X}_i^B.
\end{align}

Differentially encoding two independent shared public entropy sources $\{i,j\}$ over users $\{A,B\}$. Publicly share,
\begin{align}
\Delta_A &= [s\soplus p\soplus{\mathcal{X}}_i^A, {\mathcal{X}}_i^A \soplus {\mathcal{X}}_j^A]_A,\nonumber\\
\Delta_B &= [s\soplus p\soplus {\mathcal{X}}_i^B, {\mathcal{X}}_i^B \soplus {\mathcal{X}}_j^B]_B,\nonumber\\
%\mathtt{priv}:&\, [s\soplus \tilde{\mathcal{X}}_i, \tilde{\mathcal{X}}_i \soplus \tilde{\mathcal{X}}_j],\nonumber\\
\mathtt{pub}:&\, [s\soplus p\soplus \tilde{\mathcal{X}}_i, \tilde{\mathcal{X}}_i \soplus \tilde{\mathcal{X}}_j],
\end{align}

Encode message $m$,
\begin{align}
\mathtt{enc}(m) &= s\soplus m \soplus \tilde{\mathcal{X}}_j,\nonumber\\
%\mathtt{enc}(m) \soplus \mathtt{priv},\nonumber\\
\Delta(m) &= [s\soplus \tilde{\mathcal{X}}_i, m \soplus \tilde{\mathcal{X}}_j],
\end{align}
decode $s\soplus m$ given known $\tilde{\mathcal{X}}_i \soplus \tilde{\mathcal{X}}_j]$.

\section{Entropy codes}

Entropy codes employ random codewords,
\begin{align}
	\mathcal{X}: x \in \{0,1\}^n,
\end{align}
sampled using random variable $\mathcal{X}$ with respective per-bit Shannon entropy,
\begin{align}
	0\leq H(\mathcal{X})\leq 1.
\end{align}
Under maximum entropy $H(\mathcal{X})=1$ conditions all codewords are sampled with probability,
\begin{align}
	\mathbb{P}(x) = \frac{1}{2^n},	
\end{align}
and are orthogonal,
\begin{align}
	x_i \soplus x_j \neq \mathbf{0}.
\end{align}
Under differential encoding,
\begin{align}
	[x,x\soplus y],
\end{align}
entropy addition implies the differential term $x\soplus y$ exhibits entropy at least,
\begin{align}
	H(x\soplus y) \geq \min(H(x),H(y)).
\end{align}
Hence parity terms form unique random codewords.

For known $\{x,y\}$, its differential code $\diff{x}{y}$ affords both detection and correction of all bit-errors.

\subsection{Collision space}

The collision space of an $n$-bit function,
\begin{align}
	f_n(x) \to y,\quad x,y\in\{0,1\}^n,
\end{align}
is the number of images $y$ with multiple pre-images $x$,
\begin{align}
	\mathrm{Col}(f) = |\{\mathrm{Im}(x)\,|\,\mathrm{Im}(x)=\mathrm{Im}(y\neq x)\}|,
\end{align}
defining the non-invertible image subspace. In the collision-free subspace all images have single pre-images,
\begin{align}
	\overline{\mathrm{Col}}(f_n) + \mathrm{Col}(f_n) = 2^n,
\end{align}
paritioning the image space.

Random codes are vulnerable only when multiple secrets map to the same asymmetric encoding,
\begin{align}
	f:\, x,y \to \stackbraid{x}{x},\quad x\neq y.
\end{align}
Now the collision-free subspace of the public object is defined as secure while the collision space is insecure via pre-image ambiguity.

A birthday attack is a statistical attack on collision space where the goal is to find \emph{any} collision rather than a \emph{specific} collision, affording quadratically enhanced scaling. For an $n$-bit random bit-string with $2^n$ possible values, upon taking $k$ random samples the likelihood of finding a collision scales as,
\begin{align}
	\mathbb{P}(n,k) &\approx 1 - \exp\left[-\frac{k^2}{2^{n+1}}\right].
\end{align}
For $k=\mathrm{poly}(n)$ this ensures the asymptotic statistical security of random codewords $x$.

The collision space of asymmetric objects of the form $\stackbraid{x}{x}$ is given by the set of satisfying $y$ such that,
\begin{align}
	\stackbraid{x}{x} &= \stackbraid{y}{y},
\end{align}
the satisfiability problem of finding bit-strings which under a random braid have a given symmetric difference. This presumably mandates a brute-force search of pre-image space given that the group is the symmetric group with no hidden structure.

A braided codeword has,
\begin{align}
	c &= \stackbraid{x}{x},
\end{align}
\begin{align}
	\mathrm{Col}(c) &= \binom{n}{n/2},
\end{align}
unique pre-images as does the function,
\begin{align}
	f(x) = \stackbraid{x}{x}\oplus c.
\end{align}
If a single image is known the entire class of pre-images is trivially obtained under their known automorphisms. The pre-image space, the collision space of $f(x)$, collectively map to a single image, a homomorphism from pre-image space to image space under iterative braiding.

Under re-braiding $f(x)$ maps to a single pre-image in the collision space of $f(f(x))$,
\begin{align}
	h(x) &= f(f(x)) \nonumber\\
	&=\stackbraid{f(x)}{f(x)}\oplus c \nonumber\\
	&= \stackbraidgen{x\oplus c}{x\oplus c}{\bar{\pi}^2}{\pi^2} \oplus \stackbraid{x}{x} \oplus c.
\end{align}
Now finding the double pre-image of $h(x)$ requires finding a single pre-image from the collision space of $f(x)$, amongst,
\begin{align}
	|\mathrm{Col}(f(x))| = \binom{n}{n/2},
\end{align}
unique pre-images, only one of which has pre-image $x$. This is in general a many-to-one map where unmapped images are forbidden outcomes with multiplicity corresponding to collision space space.

The space of the available output domain is reduced by its collision space.

Can we make this bijective over the full domains under symmeterisation?

%\section{Algebraic cryptography}

\section{Permutation codes}

* Change:
\begin{align}
	R_\mathcal{X}^n = (\mathbb{Z}_{2^n}, B_n, \oplus, \star),
\end{align}
comprising the bitwise binary operators $(\mathbb{Z}_2^n,\oplus)$ and $(B_n,\pi)$, where $B_n$ is the braid group over $n$ strands, a representation of an ordered pair of permutations, $(\pi,\bar{\pi})$, where $\bar{\pi}\equiv \pi^{-1}$. Defining braids over bit-string elements...

* The algebraic structure is a non-abelian division ring.

* The codeword space for $k$ letters over $n$ bits is,
\begin{align}
	C_\mathcal{X}^k = (\mathbb{Z}_2^k,\oplus,\star) \subseteq R_\mathcal{X}^n.
\end{align}
Constraining codewords to balanced bit-strings with Hamming weight,
\begin{align}
	|x|_\mathrm{wt} = \sum_{i=1}^n x_i = \frac{n}{2},\quad\forall\, x\in\{1,k\},
\end{align}
all codewords are related by permutations,
\begin{align}
	x_i = \pi \circ x_j.
\end{align}
The permutational relations between codewords are not unique with degeneracies equivalent to the automorphism space given by the action,
\begin{align}
	\mathrm{Aut}(x) &= \mathrm{Sym}(\{x_i=0\}_i) \times \mathrm{Sym}(\{x_i=1\}_i)\nonumber\\
	\pi &\in S_{n/2} \times S_{n/2}.
\end{align}
...

Define a logical group via generators homomorphic to the automorphism space of permutational relations between bitstrings,
\begin{align}
	G_\mathcal{X}:\, &\pi\circ x_0 = x_i, \nonumber\\
	G_\mathrm{L}:\, &g_i \cdot x_0 = x_i,\quad g\equiv \mathrm{Aut}(x),\nonumber\\
	\phi:\, & G_\mathcal{X} \to G_\mathrm{L},
\end{align}
where $\phi$ is a surjective homomorphism from permutations onto their automorphisms.

--

The automorphisms of $z=x\oplus y$ are partitioned according $z$,
\begin{align}
	\mathrm{Aut}(z) &= \mathrm{Sym}(\{x_i=y_i\}_i) \times \mathrm{Sym}(\{x_i\neq y_i\}_i).
\end{align}
The only constraint imposed on $z$ is $|z|_\mathrm{wt}=2\mathbb{Z}$. While the automorphic subspaces are in general not equipartitioned via their symmetry the average case Hamming weight is,
\begin{align}
	\mu(|z|_\mathrm{wt}) = \frac{n}{2}.
\end{align}

The automorphic space of braid pre-images is partitioned over the image parity,
\begin{align}
	c_i = \pi[x]_i \oplus x_i.
\end{align}

--

We define the algebra,
\begin{align}
	(\mathbb{Z}_2^n \times S_n, \oplus,\pi),
\end{align}
comprising the bitwise binary $(\mathbb{Z}_2^n,\oplus)$ operator and the unary $(S_n,\pi)$ operator. Defining permutations over bit-string elements,
\begin{align}
	\pi &\in S_n,\nonumber\\
	\pi\circ x &\equiv x_\pi,
\end{align}
as unary operators we inherit algebraic properties from the symmetric group.
\begin{itemize}
	\item \emph{Composition}: $[\pi_i \circ \pi_j]\circ x \equiv x_{\pi_i\circ \pi_j}$.
	\item \emph{Distributivity}: $\pi\circ(x\soplus y) \equiv [x\soplus y]_\pi \equiv x_\pi \soplus y_\pi$.
\end{itemize}
For unknown $x$, the permuted bit-string $x_\pi$ can be decoded to $x$ given $\pi$.

Structures of the form,
\begin{align}
	x_\pi x \equiv x_\pi \soplus x,
\end{align}
cannot be decoded from $\pi$ alone. However, the action of $x$ or $x_\pi$ on $x_\pi x$ reveals the other,
\begin{align}
	x \soplus (x_\pi \soplus x) & = x_\pi,\nonumber\\
	x_\pi \soplus (x_\pi \soplus x) &= x.
\end{align}
Via distributivity we have the additional symmetric property,
\begin{align}
	\pi^{-1} \circ (x_\pi x)	 = x_{\pi^{-1}} x.
\end{align}

Complementation:
\begin{align}
	\overline{x_\pi \oplus x \oplus c} &= \overline{x_\pi} \oplus x \oplus c \nonumber\\
	&= x_\pi \oplus \overline{x} \oplus c \nonumber\\
	&= x_\pi \oplus x \oplus \overline{c} \nonumber\\
	&= x_\pi \oplus x \oplus c \oplus \mathbb{I}.
\end{align}
Hence,
\begin{align}
	\overline{\stackbraid{x}{x}} &= \stackbraid{\overline{x}}{x} = \stackbraid{x}{\overline{x}} = \stackbraid{x}{x} \oplus \mathbb{I}.%\nonumber\\
	%\stackbraid{\overline{x}}{\overline{x}} &= \stackbraid{x}{x}.
\end{align}
Since,
\begin{align}
	\stackbraid{\overline{x}}{\overline{x}} &= \stackbraid{x}{x},
\end{align}
braid pre-images occur in complimentary pairs, $\{x,\overline{x}\}$.

Since,
\begin{align}
	\mathrm{wt}(x_\pi) &= \mathrm{wt}(x),\nonumber\\
	\mathrm{par}(x_\pi) &= \mathrm{par}(x),
\end{align}
the parity of a braid is,
\begin{align}
	\mathrm{par}\left(\stackbraid{x}{y}\right) &= \mathrm{par}(x) \oplus \mathrm{par}(y),\nonumber\\
	\mathrm{par}\left(\stackbraid{x}{x}\right) &\in 2\mathbb{Z},
\end{align}
where,
\begin{align}
	\mathrm{wt}(x) &= \sum_i x_i,\nonumber\\
	\mathrm{par}(x) &= \bigoplus_i x_i,	
\end{align}
hence while the pre-image space is $2^n$ the image space is $2^{n-1}$ owing to the parity constraint and complimentary pairwise pre-images.

Differential codes preserve their differential structure under common global permutations but not under non-uniform permutations,
\begin{align}
	\pi\circ \diff{x}{y}	 &\equiv \diff{x_\pi}{y_\pi},\nonumber\\
 	\diff{x_\pi}{y_\pi} &\sim \diff{x}{y},\nonumber\\
	\diff{x}{y_\pi} &\not\sim \diff{x}{y} \nonumber\\
	\diff{x_\pi}{y} &\not\sim \diff{x}{y}
\end{align}

\subsection{TCF}

From the identities we construct a TCF model as,
\begin{align}
	f_\mathrm{tcf}(x) &= \stackbraid{x\oplus c}{\overline{x}\oplus \overline{c}} = \stackbraid{x\oplus c}{\overline{x}\oplus c}\nonumber\\
	&= \stackbraid{x}{\overline{x}} \oplus \stackbraid{c}{\overline{c}}\nonumber\\
	&= \stackbraid{\overline{x}}{x} \oplus \stackbraid{c}{\overline{c}}\nonumber\\
	&= \stackbraid{x\oplus c}{\overline{x}} \nonumber\\
\end{align}
which is invariant under $x\leftrightarrow \overline{x}$, defining the paired pre-images.

\begin{align}
	f_\mathrm{tcf}(x\oplus c) &= \stackbraid{x}{\overline{x}}, \nonumber\\
	f_\mathrm{tcf}(x) &= \stackbraid{x\oplus c}{\overline{x\oplus c}} = \stackbraid{\overline{x\oplus c}}{x} = w.
\end{align}
implies $\{x\oplus c, \overline{x\oplus c}\}$ form a pre-image pair,
\begin{align}
	f_\mathrm{tcf}(x\oplus c) &= 
\end{align}

Using the asymmetric hash model,
\begin{align}
	h: x\oplus \stackbraid{y}{y} \xrightarrow{\pi} \stackbraid{x}{x} \oplus y,
\end{align}
we modify to,
Using the asymmetric hash model,
\begin{align}
	f: x\oplus \stackbraid{y}{\bar{y}} \xrightarrow{\pi} \stackbraid{x}{\bar{x}} \oplus y.
\end{align}

\begin{align}
	f_\mathrm{tcf}(x) &= \stackbraid{x\oplus c}{\overline{x}\oplus \overline{c}}
\end{align}

\subsection{Braid codes}

Defining the braid operator,
\begin{align}
	\stackbraid{x}{y} &\equiv x_{\pi^{-1}} \oplus y_{\pi},
\end{align}
the braid objects exhibit trapdoor locking effects. Knowing $\pi$ does not reveal $x$ from the braid $\symbraid{x}$. Given $\symbraid{x,y}$ and $\pi$, knowing either input $x$ or $y$ reveals the other input. Hence, for known $\pi$ both inputs $x$ and $y$ act as trapdoors.

Braids preserve distributivity over $\oplus$,
\begin{align}
	\stackbraid{x}{x'} \oplus \stackbraid{y}{y'} &= \stackbraid{x\oplus y}{x'\oplus y'},\nonumber\\
	\stackbraid{x}{x} \oplus \stackbraid{y}{y} &= \stackbraid{x\oplus y}{x\oplus y}.
\end{align}

A braided differential hash operator takes the form,
\begin{align}
	\Delta(x) = \stackbraid{x}{h(x)} = x_{\pi^{-1}} \oplus h_{\pi}(x).
\end{align}

Preparing,
\begin{align}
	\Delta(s\oplus m_{\pi^{-2}}) = \stackbraid{s\oplus m}{h(s\oplus m)},
\end{align}
if $s$ is a shared secret and $\pi$ and $\Delta(s\oplus m)$ are public, sharing $h(s\oplus m)$ allows $\Delta(s\oplus m)$ to be unlocked,
\begin{align}
	&\Delta(s\oplus m) \oplus [\pi^{-1}\circ h(s\oplus m)]\nonumber\\
	&\to \symbraid{s,m} \to m,
\end{align}
where $s$ is known.

\section{Codewords}

Codewords are the space of balanced bit-strings, defining the code-space,
\begin{align}
	C_n: x\in\{0,1\}^n,\, \mathrm{wt}(x)=\frac{n}{2},\, n\in 2\mathbb{Z}^+.
\end{align}
The order of the code-space is,
\begin{align}
	|C_n| = \binom{n}{n/2}.
\end{align}
All codewords are permutations of one another,
\begin{align}
	x_i = \pi \circ x_j,\quad \pi\in S_n.
\end{align}
Code-words can be related via their permutational difference or their symmetric (XOR) difference,
\begin{align}
	x_i &= \pi \circ x_j,\nonumber\\
	x_i &= c \oplus x_j.
\end{align}

Permutations preserve Hamming weight,
\begin{align}
	\mathrm{wt}(\pi\circ x) = \mathrm{wt}(x),
\end{align}
while bit-strings symmetric differences in general do not. Code-space is therefore automorphic under the action of the symmetric group,
\begin{align}
	\mathrm{Aut}(C_n) = S_n.
\end{align}


A random permutation $\pi\in\mathcal{X}(S_n)$ applied to a codeword uniformly randomly samples another codeword,
\begin{align}
	\mathcal{X}:\quad \mathrm{Unif}(\pi\in S_n) \circ x_0 \equiv \mathrm{Unif}(x\in C_n).
\end{align}
Difference: Both sample uniformly over code-space. The former does so by uniformly sampling over transformations of an initial bit-string, while the latter samples directly. Operator sampling inherits the operator's algebraic properties, transforming code-space via a frame of reference change, affording composability and distributivity. For any chosen $\pi$ the former acts as a pseudo-random function over pre-image space $x$ while the latter is defined as a (non-pseudo) random function.

\section{Asymmetric codes}

Consider objects $s_\pi s$ and $m_\pi \cdot h(m)$, both public, where Alice knows secret $s$ and Alice knows secret $m$.
\begin{align}
	[s_\pi s] \cdot [m_\pi h(m)] &= [s \cdot m] \cdot [s_\pi \cdot h(m_\pi)]
\end{align}

We use the notation,
\begin{align}
	x_{\pi_1} y_{\pi_2} \equiv \braid{x}{y}{\pi_1}{\pi_2},\nonumber\\
	x_{\pi} x_{\pi^{-1}} \equiv \stackbraid{x}{\pi}{\pi^{-1}}.
\end{align}
If a $\pi$ index is not written it's implied the identity permutation $\pi_0$.

This encoding under pairs of permutations implies a braid representation.

Sloppily we'll also use $x\soplus y \equiv x \cdot y \equiv xy$ as shorthand.

\subsection{One-way functions}

Definition: a function $f:\{0,1\}^* \to \{0,1\}^*$ is one-way if for BPP algorithm $F$ the average case success probability of finding a pseudo-inverse is negligible,
\begin{align}
	\mathbb{P}[f(F(f(x))) = f(x)] < \mathtt{negl}(n),
\end{align}
for $x\in\mathrm{Unif}(\{0,1\}^n)$.

For random $\pi$, $y=x_\pi$ is a uniformly distributed sample over the same space as $x$, randomised under the action of $\pi$, independent of $x$.

Inverting $y=\symbraid{x}$: define $x = \hat\pi x_0$, where $x_0$ is a sorted canonical balanced bit-string used as a reference for which all $x$ may be defined relative to permutations,
\begin{align}
	x_0 &= \{0^{\times(n/2)},1^{\times(n/2)}\},\nonumber\\
	x &= \hat\pi \circ x_0,
\end{align}
for some $\hat\pi$ which are in general non-unique. The general braid $\symbraid{x}$ can be re-expressed in terms of the canonical $x_0$ as,
\begin{align}
	x_\pi x_{\pi^{-1}} &= y,\nonumber\\
	x \cdot x_{\pi^2} &= \pi[y],\quad (\pi\circ)\nonumber\\
	\hat\pi(x_0) \cdot [\pi \cdot \hat\pi (x_0)] &= y,\quad (x\to \hat\pi \cdot x_0)\nonumber\\
	x_0 \cdot [\hat\pi^{-1} \pi \cdot \hat\pi (x_0)] &= \hat\pi^{-1}(y),\quad (\hat\pi^{-1}\circ)\nonumber\\
	[\hat\pi^{-1}\cdot \pi \cdot \hat\pi](x_0) &= x_0 \cdot \hat\pi^{-1}(y),\nonumber\\
\end{align}

* Conjugacy Problem for Permutations (NP-complete): \url{https://chatgpt.com/share/5716548b-5407-4b77-947c-cc84b47c47fc}.

* Definition of CPP: Given $\sigma,\tau\in S_n$, find $\pi$ such that,
\begin{align}
	\pi\sigma\pi^{-1} = \tau.	
\end{align}

* Defining $\tau(x_0) = x_0 \cdot \hat\pi^{-1}(y)$ transforms the equation into a common reference frame relative to $x_0$.

* In the collision-free space only a single solution for $x$ exists and finding $\pi$ is equivalent to finding $x$.

* Conjugate space corresponds to collision space, separating into conjugacy classes of different orders of collisions. In the collision free regime there is exactly one conjugate solution.

%* Show that uniform sampling of $x_\pi$ implies inversion is equivalent.

%For secret $x$ we define the public object,
%\begin{align} \label{eq:one_way_sum}
%	x \xrightarrow{\pi} \selfbraid{x}{\pi}{\pi^{-1}}.
%\end{align}
%This defines a one-way function enabling verification given $x$ and $\pi$ but does not allow reverse evaluation of $x$ even if $\pi$ is known via pre-image resistance.



%The likelihood of random $x$ being a collision-free pre-image of $f: x\to \symbraid{x}$ is,
%\begin{align}
%	p &= \frac{\overline{\mathrm{Col}}(f)}{\mathrm{Col}(f)}.
%\end{align}

\subsection{Pre-image resistance}

Consider general case of arbitrary Hamming weight. Then,
\begin{align}
	\mathrm{Aut}(x) &= \mathrm{Sym}(x^{(0)}) \times \mathrm{Sym}(x^{(1)}) \nonumber\\
	&= S_{n-\mathrm{wt}(x)}\times S_{\mathrm{wt}(x)}.
\end{align}
Extreme cases of $\mathrm{wt}(x)=\{0,n\}$ we have,
\begin{align}
	\mathrm{Aut}(x) &= \mathrm{Sym}(x),
\end{align}
and the pre-image space is permutationaly invariant.

Next consider balances bit-strings,
\begin{align}
	\mathcal{X}: x\in\{0,1\}^n,\quad \mathrm{s.t.}\,\,w(x)=n/2,
\end{align}
be a random bit-string with Hamming weight \mbox{$w(x)=n/2$}. The automorphisms of $x$ are equivalent to all permutations over the subsets of elements with the same bit-value,
\begin{align}
	\mathrm{Aut}(x) &= \mathrm{Sym}(x^{(0)}) \times \mathrm{Sym}(x^{(1)}) \nonumber\\
	&= S_{n/2}\times S_{n/2}.
\end{align}
where,
\begin{align}
	x^{(k)}=\{i\,|\, x_i=k\}_{i\in x}.
\end{align}
The space of $x$ where $w(x)=n/2$ has order,
\begin{align}
	\frac{|\mathrm{Sym}(x)|}{|\mathrm{Aut}(x)|} = \frac{n!}{(\frac{n}{2})!(\frac{n}{2})!} = \binom{n}{n/2}.
\end{align}

All $x$ where $w(x)=n/2$ are related by permutations. Hence, for given $x$ and random $\pi\in S_n$, $x_\pi$ is an independent random bit-string with $w(x_\pi)=w(x)=n/2$.

In general, the pre-image space has collision space multiplicity (i.e automorphism space),
\begin{align}
	|\mathrm{Aut}(x)| = \binom{n}{\mathrm{wt}(x)}.
\end{align}

%For the entire space with unconstrained Hamming weight we have,
%\begin{align}
%	|\mathrm{Aut}| = \sum_k \binom{n}{k}
%\end{align}

Let,
\begin{align}
	x_\pi x = c,
\end{align}
be an asymmetric permutational primitive where $c$ is known and we want to find a satisfying pre-image $x$.

Consider the table,
\begin{align}
	[x_\pi,\tilde{x},\tilde{x}\soplus \tilde{c}]_i,
\end{align}
with rows over $i$, row-ordered such that the first block of $n/2$ rows have $x_i=0$ and the second block have $x_i=1$ (tilde denotes this ordering). The second and third columns are mutually order and under multiplication provide $\tilde{c}$. This is preserved under any permutation within blocks but not between blocks.

The pre-image solution corresponds to choosing $x_\pi$ such that multiplying the first column by the third column yields $\tilde{c}$.

\subsection{One-way functions}

The one-way function from Eq.~\eqref{eq:one_way_sum} acts distributively over $\soplus$,
\begin{align}
	x\soplus y \xrightarrow{\pi} \stackbraid{x}{x} \soplus \stackbraid{y}{y}.
\end{align}

%The one-way function from Eq.~\eqref{eq:one_way_sum} does not act distributively over $\soplus$,
%\begin{align}
%	(x\soplus y) &\xrightarrow{\pi} (x\soplus y)_\pi(x\soplus y)_{\pi^{-1}} \nonumber\\
%	&= x_\pi x_{\pi^{-1}} \soplus y_\pi y_{\pi^{-1}} \soplus x_\pi y_{\pi^{-1}} \soplus y_\pi x_{\pi^{-1}} \nonumber\\
%	&= \selfbraid{x}{\pi}{\pi^{-1}} \soplus  \selfbraid{y}{\pi}{\pi^{-1}} \soplus \braid{x}{y}{\pi}{\pi^{-1}} \soplus  \braid{y}{x}{\pi}{\pi^{-1}},
%\end{align}
%where,
%\begin{align}
%	\comm{x}{y}{\pi}{\pi^{-1}} \equiv \braid{x}{y}{\pi}{\pi^{-1}} \soplus \braid{y}{x}{\pi}{\pi^{-1}},
%\end{align}
%is the additive commutator of the $\xrightarrow{\pi}$ operator.

For known $x$ and unknown $y$ the object $y_\pi y$ acts as a one-time zero-knowledge proof of $y$. The proof is one-time as it is the same for all $x$.

\subsection{Hash function model}

Using the asymmetric model,
\begin{align}
	h: x\oplus \stackbraid{y}{y} \xrightarrow{\pi} \stackbraid{x}{x} \oplus y,
\end{align}
the $\braid{y}{y}{\pi}{\pi^{-1}}$ term acts a known pre-image modulation based on the hidden underlying action of unknown $\{y,\pi\}$, reproducing the property of hash pre-image salting. This provides a model for a deterministic pseudo-random hash function with hidden evaluation, while remaining verifiable.

This model implies the hash function cannot be collision free even over the same input and output domains. While in principle a function can be bijective over matching input and output domains the hash function model cannot be.

There may be an inherent underlying connection here via complexity arguments. Uniquely encoding arbitrary bijective maps \mbox{$\{0,1\}^n\to \{0,1\}^n$} has $O(2^n)$ space and time complexity. With polynomial time/space encoding this is unachievable if the function is modelled as random and unstructured.

* Collision space vanishes with $n\to\infty$, hence hash function model becomes bijective in the infinite limit. 

--

Using the model,
\begin{align}
	h(x) = \stackbraid{x}{x} \oplus c,	
\end{align}
we have,
\begin{align}
	h(x\oplus y) &= h(x)\oplus h(y) \oplus c,
\end{align}
and,
\begin{align}
	[h(x\oplus y), h(x)\oplus h(y)] = c,
\end{align}
is the additive commutator (or distributor) of the action of $h$ over its pre-image space.

\subsection{TCF model}

Using the asymmetric model,
\begin{align}
	f: x\soplus \stackbraid{x_0 x_1}{x_0 x_1} \xrightarrow{\pi} \stackbraid{x}{x} \soplus \stackbraid{x_0}{x_1}.
\end{align}

\begin{align}
	f(x_0) &= x_0^\pi x_0^{\pi^{-1}} \cdot x_0^\pi x_1^{\pi^{-1}} = x_0^{\pi^{-1}} x_1^{\pi^{-1}},\nonumber\\
	f(x_1) &= x_1^\pi x_1^{\pi^{-1}} \cdot x_0^\pi x_1^{\pi^{-1}} = x_0^{\pi} x_1^{\pi}.
\end{align}

\begin{align}
	f(x) &= x^\pi x \cdot x_0 x_1,\nonumber\\
	f(x_0) &= x_0^\pi x_0^{\pi^{-1}} \cdot x_0^\pi x_1^{\pi^{-1}} = x_0^{\pi^{-1}} x_1^{\pi^{-1}},\nonumber\\
	f(x_1) &= x_1^\pi x_1^{\pi^{-1}} \cdot x_0^\pi x_1^{\pi^{-1}} = x_0^{\pi} x_1^{\pi}.
\end{align}

\section{Encrytpion}

Given secrets $\{x,m\}$ with respective public objects $\{\stackbraid{x}{x},\stackbraid{m}{m}\}$, public information can be expressed,
\begin{align}
	\stackbraid{x}{x} \cdot \stackbraid{m}{m} &= \stackbraid{m\cdot x}{m\cdot x} \nonumber\\
	&= x_{\pi}x_{\pi^{-1}} \cdot m_\pi m_{\pi^{-1}}.
\end{align}
Now the solution revealing $m_\pi$ is,
\begin{align}
	\mathtt{sol} = x_\pi x_{\pi^{-1}} m_{\pi^{-1}},
\end{align}
hence unlocking $m$ under known $\pi$.


Applying known $\pi$ yields public,
\begin{align}
	x_{\pi^2}x \cdot m_{\pi^2} m.
\end{align}
Provision of,
\begin{align}
	\mathtt{sig} = m_{\pi^2} \cdot x_{\pi^2} \cdot x,
\end{align}
affords,
\begin{align}
	\mathtt{sig} \soplus \pi \circ \selfbraid{x\soplus m}{\pi^{-1}}{\pi} = m.
\end{align}

$\braid{x}{y}{\pi}{\pi^{-1}}$

%From the object,
%\begin{align}
%	x_\pi \soplus y,
%\end{align}
%* $y$ is released if $x$ and $\pi$ are known.\\
%* $x_\pi$ is released if $y$ is known.\\
%* $x$ is released if $\pi$ and $y$ are known.

An asymmetric trapdoor function on the differential $x\soplus y$ defined as,
\begin{align}
	[x,x\soplus y] \xrightarrow{\pi} [x, x \soplus y_\pi].
\end{align}
For known $\pi$, knowing $x$

$\pi$-symmeterised objects are pre-image resistant and public-safe, while their pre-images are not.

Via composition, differential codes for $\pi$-symmeterised objects preserve differentiality of their pre-image codes,
\begin{align}
	\diff{x}{y} \Rightarrow \diff{x_\pi x}{y_\pi y}.
\end{align}

Defining a secret key $s$ and public key $s\soplus p$ differentially we obtain,
\begin{align}
	\diff{s}{p} &= [s, s\soplus p],\nonumber\\
	[s, s\soplus p] &= [p\soplus s, p],\nonumber\\
	\diff{s_\pi s}{p_\pi p} &= [s\soplus p, s_\pi\soplus p_\pi],\nonumber\\
\end{align}

Similarly defining a message $m$ differentially encoded against the same secret key $s$ we have,
\begin{align}
	\diff{s}{m} = [s,s\soplus m].
\end{align}

Under composition this implies,
\begin{align}
	[s,s\soplus p] \soplus [s,s\soplus m] = [\mathbf{0},p\soplus m].	
\end{align}

Hence treating differential terms as shared information affords evaluation of $p\soplus m$ independent of $s$.

Introduce the term asymmetric term $m_\pi h(m)$ encoding a permuted message against its hash.

%$m_\pi h(m) \soplus $

Let us introduce symmetrised public terms,
\begin{align}
	s_\pi s, \nonumber\\
	p_\pi p.	
\end{align}

Using the permuted differential codes we have the identity,
\begin{align}
	[s,s \soplus p] \soplus [s, s_\pi \soplus m_\pi] = [\mathbf{0}, s_\pi s \soplus m_\pi p].
\end{align}

\begin{align}
	[s,s \soplus p] \soplus [p,p_\pi \soplus m_\pi] = [\mathtt{pk}, p_\pi s \soplus m_\pi p].
\end{align}

If the differential term is publicly shared this affords decoding under,
%\begin{align}
%	(m_\pi p) \soplus (m) = m
%\end{align}

\section{Old}

We define asymmetric key-pairs via their differential encoding,
\begin{align}
	\mathtt{sk}, \mathtt{pk} &\in \{0,1\}^n,
\end{align}

\begin{align}
	\kp &= \diff{\sk}{\pk} \nonumber\\
	&= [\sk,\sk \soplus \pk],
\end{align}

\section{Digital signatures}

Generate signature,
\begin{align}
	\sig(m,\sk) &= \diff{\sk}{\pk} \soplus \diff{\sk}{m} \nonumber\\
	&= \diff{\mathbf{0}}{\pk\soplus m} \nonumber\\
	&= \pk \soplus m.
\end{align}

Verify signature,
\begin{align}
	\ver(\sig,\pk) &= \Delta(m,\pk) \soplus \Delta() \nonumber\\
	&= \pk.
\end{align}

\section{Asymmetric encryption}

Encode,
\begin{align}
	\tilde{m} &= \enc(m,\pk) \nonumber\\
	&= \diff{m}{\sk} \nonumber\\
	&= \sk \soplus m.
\end{align}

Decode,
\begin{align}
	\dec(\tilde{m},\sk) &= \tilde{m} \soplus \bar\kp \nonumber\\
	&= \enc(\sk,m) \soplus \diff{\pk}{\sk} \nonumber\\
	&= \sk \soplus m.
\end{align}

\section{Authentication}

* $auth = (s1+p1)+(s2+p2) = p1+p2$

\section{Key reuse}

Consider multiple messages $m_i$ signed by the same public key,
\begin{align}
	\enc(m_i,\pk) &= \pk \soplus m_i, \nonumber\\
\end{align}

Verify signature,
\begin{align}
	\ver(\sig,\pk) &= \Delta(m,\pk) \soplus \Delta() \nonumber\\
	&= \pk.
\end{align}

\subsection{Key-establishment \& secret sharing}

\section{Old stuff}

\section{Differential hash codes}

A pair of bit-strings $\{x,y\}$ may be expressed differentially using the tuple,
\begin{align}
	[x,x\soplus y]_\soplus,
\end{align}
where the differential term $x\soplus y$ alone reveals no information about $x$ or $y$ while the non-differential term unlocks the code to reveal both. The validity of differentially encoded tuples may be trivially confirmed given knowledge of both terms.

We define the differential hash operators,
\begin{align}
	\Delta(x) &= h(x)\soplus x,\nonumber\\
	\Delta_\pi(x) &= h(x_\pi)\soplus x,
\end{align}
where $\pi\in S_n$ for $x\in\{0,1\}^n$ is a permutation over the elements of $x$. These encode a hash's image and pre-image together while revealing neither assuming hash pre-image resistance. We have the properties,
\begin{align}
	h(x) &= \Delta(x) \soplus x,\nonumber\\
	x &= \Delta(x) \soplus h(x).
\end{align}
The $\Delta$ operator inherits pre-image resistance from $h(\cdot)$. Knowing $\Delta(x)$ alone reveals neither $x$ nor $h(x)$, however additionally knowing $x$ or $h(x)$ enables verification of $\Delta(x)$. Finding $x$ for given $\Delta(x)$ reduces to the pre-image resistance of the hash function $h(\cdot)$.

The non-differentially encoded tuple $\{x,h(x)\}$ allows $x$ to unlock $h(x)$, while $h(x)$ cannot unlock $x$. The second element reveals $h(x)$ alone, but not $x$ via pre-image resistance. Under the differential encoding,
\begin{align}
	[x,\Delta(x)]_\soplus =[x,h(x)\soplus x]_\soplus,
\end{align}
the second element reveals neither $x$ nor $h(x)$, while the first element reveals both, given that $h(x)$ can be efficiently forward-evaluated. Alternately, under the differential encoding,
\begin{align}
	[h(x),\Delta(x)] = [h(x),h(x)\soplus x],
\end{align}
the non-differential term $h(x)$ affords unlocking the code but does not on its own reveal $x$ via hash pre-image resistance. Under both encodings knowing either $x$ or $h(x)$ alone enables verification.

The differential operator is distributive only over its unhashed components,
\begin{align}
	\Delta(x\soplus y) &= h(x\soplus y)\soplus x\soplus y \nonumber\\
	\Delta(x)\soplus\Delta(y) &= h(x)\soplus h(y)\soplus x\soplus y.
\end{align}
%Thus knowing $h(x\soplus y)$ does not unlock the object, whereas knowing both $x$ and $y$ does.

%Tuples of the form,
%\begin{align}
%	D(x,h(x)) &= [x, \Delta(x)], \nonumber\\
%	D(h(x),x) &= [h(x), \Delta(x)],
%\end{align}
%provide alternate differential encodings for $\{x,h(x)\}$, both affording efficient verification. A convenience is to collect terms known to different parties over the two sides of the encoding. Under both encodings knowing either $x$ or $h(x)$ unlocks both.

% We will generally treat the differential term as public and the non-differential term as private information.

%Taking bit-permuted tuples of this form, hash verification only succeeds if the correct inverse permutation is first applied.

%\subsection{Algebraic properties}

The symmetric difference between $\Delta(x\soplus y)$ and $\Delta(x)\soplus\Delta(y)$ gives the `distributor' (equivalent of commutator for distributivity),
\begin{align}
	\Delta(x\soplus y)\soplus \Delta(x)\soplus \Delta(y) = h(x\soplus y) \soplus h(x)\soplus h(y),
\end{align}
defining the distributivity of $\Delta$ operator over the action of $\soplus$.

Standard differential codes are composable,
\begin{align}
	[x,x\soplus y)]_\soplus \soplus [x',x'\soplus y']_\soplus\nonumber\\
	\sim [x\soplus x', x\soplus y \soplus x' \soplus y']_\soplus.
\end{align}
For differential hash codes,
\begin{align}
	[x,\Delta(x)]_\soplus,\nonumber\\
	[y,\Delta(y)]_\soplus,
\end{align}
we have distinct composition rules,
\begin{align}
	[x\soplus y,\Delta(x\soplus y)]_H,\nonumber\\
	[x\soplus y,\Delta(x) \soplus \Delta(y))]_\soplus.
\end{align}
The $[\cdot,\cdot]_H$ composition is verifiable by hashing the left hand term. The $[\cdot,\cdot]_\soplus$ composition is not hash-verifiable but preserves all differential encoding constraints.

Permutations $\pi$ are distributive over $\soplus$ but not commutative,
\begin{align}
	\pi(x\soplus y) &= \pi(x) \soplus \pi(y),\nonumber\\
	\pi(x) \soplus y &\neq x \soplus \pi(y),
\end{align}
whereas $\soplus$ is commutative but not distributive (in general, depending on parity of number of terms under distribution),
\begin{align}
	x\soplus y &= y \soplus x.
\end{align}

\begin{itemize}
	\item $h(m\soplus s)$ will reveal the private $h(s)$ for chosen $m=\mathbf{0}$.
	\item $h(m\soplus s \soplus x)$ will reveal the private $h(x)$ for chosen $m=x$ if $x$ is public.
	\item $h(\pi(m\soplus s)) = h(m_\pi \soplus s_\pi)$ can only reveal $h(s_\pi)$ (not secret) for public $\pi$ and chosen $m$, but cannot reveal secret $h(s)$.
\end{itemize}

\section{Asymmetric codes}

We define key-pairs as,
\begin{align}
	\mathtt{sk} &\in \{0,1\}^n, \nonumber\\
	\mathtt{pk} &= \{\mathtt{pk}_\Delta,\mathtt{pk}_\pi\},\nonumber\\
	\mathtt{pk}_\Delta &= \Delta(\mathtt{sk}),\nonumber\\
	\mathtt{pk}_\pi &\in S_n,
\end{align}
where $\mathtt{sk}$ be a secret bit-string, $h(\{0,1\}^n)\to\{0,1\}^n$ an $n$-bit endomorphic hash function, and $\pi\in S_n$ a permutation on $n$ bits. Since $|S_n|=n!$ encoding $\pi$ requires $\lceil\log_2(n!)\rceil$ bits. For $n=256$ we have $\lceil\log_2(n!)\rceil = 1684$ bits.

%and,
%\begin{align}
%	\pi &= h(\Delta(\mathtt{sk})),
%\end{align}
%is a non-unlocking public identifier, where,
%\begin{align}
%	x_\pi \equiv x\soplus h(\pi).
%\end{align}
Since $\mathtt{pk} = \Delta(\mathtt{sk})$ is public both $\mathtt{sk}$ and $h(\mathtt{sk})$ must be private to prevent unlocking the public key, both acting as trapdoors for the differential encoding.


%The signature confirms consistency between private and public information while revealing only $h(\mathtt{sk}_pi)$ about the private key. To use Alice's private key as $s$ we inhibit the disclosure of $\mathtt{sk}$ by applying a publicly known pre-image manipulation prevents the signature from revealing the secret key, instead using,

\begin{align}
	[m_\pi \soplus s_\pi, \Delta_\pi(m_\pi\soplus s_\pi)],
\end{align}

\begin{align}
	\Delta_\pi(m_\pi\soplus s_\pi) &= \Delta_\pi(m_\pi) \Delta_\pi(s_\pi) \nonumber\\
	&\soplus h(m_\pi) \soplus h(s_\pi) \soplus h(m_\pi \soplus s_\pi)
\end{align}

%Hence for,
%\begin{align}
%	[\mathtt{sig}, \Delta_\pi(m_\pi) \soplus \Delta(s_\pi)],
%\end{align}
%we require,
%\begin{align}
%	h(\mathtt{sig}) = \Delta_\pi(m_\pi) \soplus \Delta(s_\pi) \soplus h(m_\pi) \soplus h(s_\pi).
%\end{align}


%--
%We will employ the two alternate differential encodings as asymmetric primitives,
%\begin{align}
%	&[m\soplus s, \Delta(h(m)\soplus s)],\nonumber\\
%	&[h(m)\soplus s, \Delta(m\soplus s)],
%\end{align}
%with the identities,
%\begin{align}
%	\Delta(m\soplus s) &= \Delta(m)\soplus \Delta(s) \soplus h(m\soplus s) \soplus h(m)\soplus h(s),\nonumber\\
%	\Delta(h(m)\soplus s) &= \Delta(m)\soplus \Delta(s) \soplus h(h(m)\soplus s) \soplus m\soplus h(s).
%\end{align}
%
%\begin{align} 
%	\Delta(m)\soplus \Delta(s) &= \Delta(m\soplus s) \soplus h(m\soplus s) \soplus h(s) \soplus h(m),\nonumber\\
%\end{align}
%
%\begin{align} 
%	\Delta(m)\soplus \Delta(s) &= \Delta(m\soplus s) \soplus h(m\soplus s) \soplus h(s) \soplus h(m),\nonumber\\
%\end{align}
%
%---
%
%
%\begin{align}
%	\Delta(m_\pi \soplus s) &= h(m_\pi \soplus s) \soplus m_\pi \soplus s,\nonumber\\
%	\Delta(m_\pi) \soplus \Delta(s) &= h(m_\pi) \soplus h(s) \soplus m_\pi \soplus s,
%\end{align}
%
%Assume the message is known,
%\begin{align}
%	\Delta(m_\pi \soplus s_\pi) &= h(m_\pi \soplus s_\pi) \soplus m_\pi \soplus s_\pi \nonumber\\
%	&= \Delta(m_\pi) \soplus \Delta(s) \soplus h(m_\pi \soplus s) \soplus m_\pi \soplus s_\pi.
%\end{align}
%
%\begin{align}
%	\Delta(m_\pi \soplus s_\pi) = \Delta(m_\pi) \soplus \Delta(s) \soplus h(m_\pi \soplus s) \soplus m_\pi \soplus s.
%\end{align}
%
%%\begin{align}
%%	\Delta(s_\pi) &= h(s_\pi) \soplus s_\pi, \nonumber\\
%%	\Delta(s) &= \Delta(s_\pi) \soplus h(s_\pi) \soplus s_\pi.
%%\end{align}
%
%
%Hence (2): given $\Delta(m_\pi)$ Alice can extract the message via,
%\begin{align}
%		m = \Delta(\pi \soplus m) \soplus \Delta(s) \soplus h(\pi \soplus m) \soplus \pi,
%\end{align}
%
%--
%
%\begin{align}
%	&[h(m_\pi \soplus s_\pi), \Delta(m_\pi \soplus s_\pi)],\nonumber\\
%	&[h(m_\pi \soplus s_\pi), \Delta(m_\pi ) \soplus \Delta(s_\pi) \soplus h(m_\pi) \soplus h(s_\pi) \soplus h(m_\pi  \soplus s_\pi))],\nonumber\\
%\end{align}
%
%\begin{align}
%	h(m_\pi \soplus s_\pi) &= \Delta(m_\pi) \soplus \Delta(s_\pi) \nonumber\\
%	&\soplus h(m_\pi) \soplus h(s_\pi) \soplus h(m_\pi \soplus s_\pi),\nonumber\\
%\end{align}

\section{Digital signatures}

To sign message \mbox{$m\in\{0,1\}^n$} Alice makes public the differentially encoded, signed message $\Delta(m_\pi)$ and signature,
\begin{align}
	 \mathtt{sig}_\pi(m) = h(m_\pi \soplus \mathtt{sk}_\pi).
\end{align}
The signature has the property that when combined with public information it reveals the hash of the message being signed,
\begin{align}
	 \mathtt{sig}_\pi(m) \soplus \Delta(m) \soplus \Delta(\mathtt{sk}_\pi) = h(m).
\end{align}
Employing the modulated public key $\Delta(\mathtt{sk}_\pi)$,
\begin{align}
	\mathtt{sk}_\pi \equiv \mathtt{sk} \soplus h(\mathtt{pk}),
\end{align}
prevents the signature from revealing the trapdoor $h(\mathtt{sk})$ which unlocks the public key,
\begin{align}
	h(\mathtt{sk}) \soplus \Delta(\mathtt{sk}) &= \mathtt{sk},\nonumber\\
	h(\mathtt{sk}_\pi) \soplus \Delta(\mathtt{sk}) &\neq \mathtt{sk}.
\end{align}

%To verify Alice's signature Bob evaluates,
%\begin{align}
%	\mathtt{sig}_\pi(m) \soplus \Delta(s_\pi) \soplus \Delta(m) = m,
%\end{align}
%revealing $m$, which can be compared against its hash to verify the signature's validity.

%Taking Eq.~\eqref{eq:diff_sol} and grouping public information on the right we obtain,
%\begin{align}
%	h(m\soplus s) &= \Delta(m)\soplus \Delta(s),\nonumber\\
%	\mathtt{sig} &= h(m\soplus s).
%\end{align}

\section{Encryption}

For asymmetric encryption we reverse the roles of $m$ and $h(m)$. Bob wishes to send message $m$ to Alice and makes public,
\begin{align}
	\mathtt{enc}(m) &= \{\Delta(m), h(m)\}. 
\end{align}
Alice now decrypts using the message hash $h(m)$ to reveal the original message,
\begin{align}
	\Delta(s_\pi) \soplus \Delta(m) \soplus h(m) = m.
\end{align}

\subsection{Multi-sigs}

Signatures are commutative, additive and composable.
\begin{align}
	\mathtt{sig}_\pi(m) = \Delta(s_\pi) \soplus h(m),
\end{align}

\subsection{Key-establishment \& secret sharing}

Using the asymmetric encryption protocol, Alice finally communicates the verification hash,
\begin{align}
	\mathtt{key} = h(\mathtt{sk}\soplus m),
\end{align}
back to Bob, who also able to verify its validity. The verification hash now provides confirmation of a jointly prepared hash-based random number given by  the XOR-salted hash of Alice's secret key and Bob's chosen salt, which cannot be spoofed by either.

\section{Notes}

* The hash collision space translates to decoding failure.

Differentially encoded tuples are composable under bitwise XOR,
\begin{align}
	[x,\Delta(x)] \soplus [y,\Delta(y)] = [x\soplus y, \Delta(x)\soplus \Delta(y)],
\end{align}
via the commutativity of $\soplus$.

Compare above rhs,
\begin{align}
	h(x\soplus y) \soplus x \soplus y = h(x \soplus y) \soplus h(x) \soplus h(y).
\end{align}

$\pi$ known by inverting $\pi$ and multiplying the tuple elements to confirm consistency. For unknown or incorrect $\pi$ hash verification fails.

The bit permutation operator, $\pi(\cdot)$, is distribute over the bit-wise XOR operator, $\soplus$,
\begin{align}
	\pi(x)\soplus \pi(y) = \pi(x\soplus y).
\end{align}
Hence differential encoding relationships are preserved under the uniform action of $\pi$,
\begin{align}
	[x,x\soplus y] &\sim [\pi(x), \pi(x\soplus y)],
\end{align}
but are in general not preserved under non-uniform action of $\pi$,
\begin{align}
	[x,x\soplus y] \not\sim [\pi(x), x\soplus y].
\end{align}
We'll employ the shorthand,
\begin{align}
	\pi\circ[x,y] = [\pi(x),\pi(y)].,
\end{align}
to denote the uniform action of $\pi$ over a differential code.

While permutations are distributive over $\soplus$ they do not commute through hashes,
\begin{align}
	\pi(h(x)) \neq h(\pi(x)).	
\end{align}

\begin{align}
	\Delta(\pi(x\soplus y)) = h(\pi(x\soplus y)) \soplus \pi(x) \soplus \pi(y).
\end{align}

\subsection{Symmetric encryption}

Consider a single shared secret random bit-string differentially encoded against unique, single-use random bit-strings, also secret,
\begin{align}
	s &\in \{0,1\}^n,,\nonumber\\
	\mathcal{X}_i &\in \{0,1\}^n,\nonumber\\
	&[s,s\soplus \mathcal{X}_i].
\end{align}

Two parties $\{i,j\}$ publicly share their differential terms yielding the respective private and public terms,
\begin{align}
	\mathtt{Priv}:\, &\{s,\mathcal{X}_i,\mathcal{X}_j,\mathcal{X}_{i,j}\} \sim \langle s,\mathcal{X}_i,\mathcal{X}_j \rangle\nonumber\\
	&\sim \mathrm{GF}(2^3),\nonumber\\
	\mathtt{Pub}:\, &\{s\soplus \mathcal{X}_i, s\soplus \mathcal{X}_j, \mathcal{X}_{i,j} \}\nonumber\\
	&\sim \langle s\soplus \mathcal{X}_i,s\soplus \mathcal{X}_j \rangle \sim \langle \mathcal{X}_i,\mathcal{X}_j \rangle \times \langle s\rangle \nonumber\\
	&\sim \mathrm{GF}(2^2),
\end{align}
where,
\begin{align}
	\mathcal{X}_{i,j} = \mathcal{X}_i\soplus\mathcal{X}_j,
\end{align}
is a jointly established publicly-known random variable obtained under addition of both parties' communicated differential terms.

If $i$ wishes to send a message to $j$ they prepare,
\begin{align}
	[s, s\soplus m \soplus \mathcal{X}_i],
\end{align}
which can be differentially decoded from $s$ given $\mathcal{X}_i$.

Publicly communicating the differential term, the spaces of private and public information form groups with group generators given by privately held and publicly shared objects,
\begin{align}
	G_\mathrm{priv} &\sim \mathrm{GF}(2^4) \sim \langle s,m,\mathcal{X}_i,\mathcal{X}_j \rangle, \nonumber\\
	G_\mathrm{pub} &\sim \mathrm{GF}(2^3) \sim \langle s\soplus \mathcal{X}_i, s\soplus \mathcal{X}_j, s\soplus m\rangle,
\end{align}
with respective group elements under binary addition (XOR),
\begin{align}
	G_\mathrm{pub}:\, &\{\emptyset, \mathcal{X}_{i,j},\nonumber\\
	&s\soplus \mathcal{X}_i, s\soplus \mathcal{X}_j,\nonumber\\
	 &m\soplus \mathcal{X}_i, m\soplus\mathcal{X}_j,\nonumber\\
	 &s\soplus m\soplus \mathcal{X}_{i,j}\},\nonumber\\
	G_\mathrm{priv}:\, &\{s,m,\mathcal{X}_i,\mathcal{X}_j\} \times \langle G_\mathrm{pub} \rangle,
\end{align}
Now public information reveals $m\soplus s$ but not $m$ or $s$ individually whereas the additional private information does.

Define a pair of secrets $\{s,p\}$,
\begin{align}
	[s, s\soplus p],
\end{align}
let us instead encode $m$ against $p$,
 \begin{align}
	[p, m\soplus p \soplus \mathcal{X}_i].
\end{align}

Then the public and private groups are generated by,
\begin{align}
	G_\mathrm{priv} &\sim \langle s,p,m,\mathcal{X}_i,\mathcal{X}_j \rangle, \nonumber\\
	G_\mathrm{pub} &\sim \langle s\soplus \mathcal{X}_i, s\soplus \mathcal{X}_j, p\soplus m\soplus \mathcal{X}_i \rangle \nonumber\\
	&= \{ \mathcal{X}_{i,j}, s\soplus \mathcal{X}_i, s\soplus \mathcal{X}_j, \nonumber\\
	&\quad p\soplus m\soplus \mathcal{X}_i, p\soplus m\soplus \mathcal{X}_j, \nonumber\\
	&\quad s\soplus p \soplus m, s \soplus p\soplus m \soplus \mathcal{X}_{i,j} \}.
\end{align}
%Now the group structure of $G_\mathrm{pub}$ is independent of $s$ and its group elements are,
%\begin{align}
%G_\mathrm{pub} &\sim \langle s\soplus \mathcal{X}_i, s\soplus \mathcal{X}_j, p\soplus s\soplus m\rangle \nonumber\\
%	&= \{\mathcal{X}_{i,j}, s\soplus \mathcal{X}_i, s\soplus \mathcal{X}_j, p\soplus s\soplus m\}.	
%\end{align}

%\begin{align}
%	\mathtt{Pub}:\, &\langle s\soplus \mathcal{X}_i, p\soplus \mathcal{X}_j \rangle \sim \{ s\soplus \mathcal{X}_i, p\soplus \mathcal{X}_j, s\soplus p \soplus \mathcal{X}_{i,j} \}.
%\end{align}

--

HERE:

Sending the encoded message $m\soplus s \soplus \mathcal{X}_{j}$ (one-time-pad encoding against $s\soplus \mathcal{X}_{i,j}$) we obtain the groups,
\begin{align}
	\mathtt{Priv}:\, &\langle s, p, m, \mathcal{X}_i, \mathcal{X}_j\rangle,\nonumber\\
	\mathtt{Pub}:\, &\langle s\soplus \mathcal{X}_i, p\soplus \mathcal{X}_j, m \soplus s \soplus \mathcal{X}_{i,j} \rangle \nonumber\\
	\sim &\{ s\soplus \mathcal{X}_i, p\soplus \mathcal{X}_j, s\soplus p\soplus \mathcal{X}_{i,j},\nonumber\\
	&m \soplus \mathcal{X}_j, m \soplus p \soplus \mathcal{X}_i,\nonumber\\
	& \} %m \soplus \mathcal{X}_{i,j}, s\soplus p\soplus m \}.
\end{align}

--

\begin{align}
	A &\to [s_i,s_i\soplus \mathcal{X}_i], \nonumber\\	
	B &\to [p_j,p_j\soplus \mathcal{X}_j], \nonumber\\	
	A,B &\gets [s_i \soplus p_j, s_i\soplus p_j\soplus \mathcal{X}_{i,j}],\nonumber\\
%	B &\to [s, s\soplus \mathcal{X}_i \soplus \mathcal{X}_j], \nonumber\\
%	A,B &\gets \{\mathcal{X}_i, \mathcal{X}_j \}, \nonumber\\
	E &\gets \{s_i \soplus \mathcal{X}_i, p_j \soplus \mathcal{X}_j,s_i \soplus p_j \soplus \mathcal{X}_{i,j} \},\nonumber\\
	A &\to [p_j, p_j \soplus m\soplus \mathcal{X}_i],\nonumber\\
	B &\gets m,\nonumber\\
	E &\gets \{s\soplus \mathcal{X}_i, s \soplus \mathcal{X}_{i,j},\mathcal{X}_j,\nonumber\\
	&\quad p\soplus m \soplus \mathcal{X}_i, p\soplus s\soplus m \} 
\end{align}


--

Upon publicly communicating only the differential terms other parties in possession of $s$ can decode all $x_i$. Upon repeating using independent samples of $x_i$ but with the same secret Eve is in possession of $s\soplus x_i$ for each sample. Combining multiple interceptions Eve can produce,
\begin{align}
	s\soplus x_i \soplus s \soplus x_j &= x_i \soplus x_j,
\end{align}
which is independent of $s$ and reveals no information about $s$ in the absence of knowing any $x_i$. Thus over $n$ iterations the parties securely share $\{x\}$ where all $x_i$ are statistically independent, maximum entropy random variables. Concatenation enables a finite length shared secret to facilitate the secure sharing of arbitrarily long random bit-strings which can subsequently be employed in a one-time pad cipher, affording statistical security bounded by the entropy rate.

The security of $s\soplus x$ can be information-theoretically interpreted in terms of the mutual information between the secret $s$ and public information in $s\soplus x$. For random variables $X$ and $Y$ their mutual information is given by,
\begin{align}
	I(X;Y) = H(X) + H(Y) - H(X,Y).	
\end{align}
Let,
\begin{align}
 	&X\equiv \{s,x\},\nonumber\\
 	&Y\equiv s\soplus x,
\end{align} 
where $X$ denotes private information and $Y$ public information. We have the identities,
\begin{align}
 	H(X) &\leq H(Y) \leq 1,\nonumber\\
	H(X,Y) &= 2H(X),\nonumber\\
	I(X;Y) &= 2H(X)-H(X,Y)\nonumber\\
	&= 0,\nonumber\\
	I(E) &= I(X_s;Y) = I(X_x;Y)\nonumber\\
	&= H(X)+H(Y)-H(X,Y)\nonumber\\
	&= H(Y) - H(X)\nonumber\\
	&\leq 1-H(X).
\end{align}
Hence the mutual information between either private random variables and the encoded public random variable, equivalently the extractable information by an eavesdropper, is upper bounded by $1-H(X)$ where $0\leq H(X)\leq 1$. For perfect entropy sources where $H(X)=1$ this implies zero information leakage to Eve.

\subsubsection{Quantum key distribution}

QKD can be equivalently conceptualised. Consider the entanglement-based E91 QKD protocol where for each Bell pair Alice and Bob choose random measurement bases with random measurement outcomes,
\begin{align}
	b_{A,B} &\in \{Z\equiv 0, X\equiv 1\},\nonumber\\
	m_{A,B} &\in \{0,1\}.
\end{align}
Post-selecting on outcomes where the measurement bases chosen by Alice and Bob are consistent, their respective measurement outcomes are dictated by parity constraints,
\begin{align}
	m_A\soplus m_B = p_b,\quad (b_A=b_B,\, p_b\in\{0,1\}).
\end{align}
where $p_b$ is imposed by the choice of Bell pair and measurement basis. Under this model for QKD security is statistical and associated with the entropy of $b$ and $m$, mediated by entanglement enforcing their parity constraints.

\section{Asymmetric codes}

We define key-pairs as,
\begin{align}
	\mathtt{sk} &\in \{0,1\}^n, \nonumber\\
	\mathtt{pk} &= \{\mathtt{pk}_\Delta,\mathtt{pk}_\pi\},\nonumber\\
	\mathtt{pk}_\Delta &= \Delta(\mathtt{sk}),\nonumber\\
	\mathtt{pk}_\pi &\in S_n,
\end{align}
where $\mathtt{sk}$ be a secret bit-string, $h(\{0,1\}^n)\to\{0,1\}^n$ an $n$-bit endomorphic hash function, and $\pi\in S_n$ a permutation on $n$ bits. Since $|S_n|=n!$ encoding $\pi$ requires $\lceil\log_2(n!)\rceil$ bits. For $n=256$ we have $\lceil\log_2(n!)\rceil = 1684$ bits.

%and,
%\begin{align}
%	\pi &= h(\Delta(\mathtt{sk})),
%\end{align}
%is a non-unlocking public identifier, where,
%\begin{align}
%	x_\pi \equiv x\soplus h(\pi).
%\end{align}
Since $\mathtt{pk} = \Delta(\mathtt{sk})$ is public both $\mathtt{sk}$ and $h(\mathtt{sk})$ must be private to prevent unlocking the public key, both acting as trapdoors for the differential encoding.


%The signature confirms consistency between private and public information while revealing only $h(\mathtt{sk}_pi)$ about the private key. To use Alice's private key as $s$ we inhibit the disclosure of $\mathtt{sk}$ by applying a publicly known pre-image manipulation prevents the signature from revealing the secret key, instead using,

\begin{align}
	[m_\pi \soplus s_\pi, \Delta_\pi(m_\pi\soplus s_\pi)],
\end{align}

\begin{align}
	\Delta_\pi(m_\pi\soplus s_\pi) &= \Delta_\pi(m_\pi) \Delta_\pi(s_\pi) \nonumber\\
	&\soplus h(m_\pi) \soplus h(s_\pi) \soplus h(m_\pi \soplus s_\pi)
\end{align}

%Hence for,
%\begin{align}
%	[\mathtt{sig}, \Delta_\pi(m_\pi) \soplus \Delta(s_\pi)],
%\end{align}
%we require,
%\begin{align}
%	h(\mathtt{sig}) = \Delta_\pi(m_\pi) \soplus \Delta(s_\pi) \soplus h(m_\pi) \soplus h(s_\pi).
%\end{align}


%--
%We will employ the two alternate differential encodings as asymmetric primitives,
%\begin{align}
%	&[m\soplus s, \Delta(h(m)\soplus s)],\nonumber\\
%	&[h(m)\soplus s, \Delta(m\soplus s)],
%\end{align}
%with the identities,
%\begin{align}
%	\Delta(m\soplus s) &= \Delta(m)\soplus \Delta(s) \soplus h(m\soplus s) \soplus h(m)\soplus h(s),\nonumber\\
%	\Delta(h(m)\soplus s) &= \Delta(m)\soplus \Delta(s) \soplus h(h(m)\soplus s) \soplus m\soplus h(s).
%\end{align}
%
%\begin{align} 
%	\Delta(m)\soplus \Delta(s) &= \Delta(m\soplus s) \soplus h(m\soplus s) \soplus h(s) \soplus h(m),\nonumber\\
%\end{align}
%
%\begin{align} 
%	\Delta(m)\soplus \Delta(s) &= \Delta(m\soplus s) \soplus h(m\soplus s) \soplus h(s) \soplus h(m),\nonumber\\
%\end{align}
%
%---
%
%
%\begin{align}
%	\Delta(m_\pi \soplus s) &= h(m_\pi \soplus s) \soplus m_\pi \soplus s,\nonumber\\
%	\Delta(m_\pi) \soplus \Delta(s) &= h(m_\pi) \soplus h(s) \soplus m_\pi \soplus s,
%\end{align}
%
%Assume the message is known,
%\begin{align}
%	\Delta(m_\pi \soplus s_\pi) &= h(m_\pi \soplus s_\pi) \soplus m_\pi \soplus s_\pi \nonumber\\
%	&= \Delta(m_\pi) \soplus \Delta(s) \soplus h(m_\pi \soplus s) \soplus m_\pi \soplus s_\pi.
%\end{align}
%
%\begin{align}
%	\Delta(m_\pi \soplus s_\pi) = \Delta(m_\pi) \soplus \Delta(s) \soplus h(m_\pi \soplus s) \soplus m_\pi \soplus s.
%\end{align}
%
%%\begin{align}
%%	\Delta(s_\pi) &= h(s_\pi) \soplus s_\pi, \nonumber\\
%%	\Delta(s) &= \Delta(s_\pi) \soplus h(s_\pi) \soplus s_\pi.
%%\end{align}
%
%
%Hence (2): given $\Delta(m_\pi)$ Alice can extract the message via,
%\begin{align}
%		m = \Delta(\pi \soplus m) \soplus \Delta(s) \soplus h(\pi \soplus m) \soplus \pi,
%\end{align}
%
%--
%
%\begin{align}
%	&[h(m_\pi \soplus s_\pi), \Delta(m_\pi \soplus s_\pi)],\nonumber\\
%	&[h(m_\pi \soplus s_\pi), \Delta(m_\pi ) \soplus \Delta(s_\pi) \soplus h(m_\pi) \soplus h(s_\pi) \soplus h(m_\pi  \soplus s_\pi))],\nonumber\\
%\end{align}
%
%\begin{align}
%	h(m_\pi \soplus s_\pi) &= \Delta(m_\pi) \soplus \Delta(s_\pi) \nonumber\\
%	&\soplus h(m_\pi) \soplus h(s_\pi) \soplus h(m_\pi \soplus s_\pi),\nonumber\\
%\end{align}

\section{Digital signatures}

To sign message \mbox{$m\in\{0,1\}^n$} Alice makes public the differentially encoded, signed message $\Delta(m_\pi)$ and signature,
\begin{align}
	 \mathtt{sig}_\pi(m) = h(m_\pi \soplus \mathtt{sk}_\pi).
\end{align}
The signature has the property that when combined with public information it reveals the hash of the message being signed,
\begin{align}
	 \mathtt{sig}_\pi(m) \soplus \Delta(m) \soplus \Delta(\mathtt{sk}_\pi) = h(m).
\end{align}
Employing the modulated public key $\Delta(\mathtt{sk}_\pi)$,
\begin{align}
	\mathtt{sk}_\pi \equiv \mathtt{sk} \soplus h(\mathtt{pk}),
\end{align}
prevents the signature from revealing the trapdoor $h(\mathtt{sk})$ which unlocks the public key,
\begin{align}
	h(\mathtt{sk}) \soplus \Delta(\mathtt{sk}) &= \mathtt{sk},\nonumber\\
	h(\mathtt{sk}_\pi) \soplus \Delta(\mathtt{sk}) &\neq \mathtt{sk}.
\end{align}

%To verify Alice's signature Bob evaluates,
%\begin{align}
%	\mathtt{sig}_\pi(m) \soplus \Delta(s_\pi) \soplus \Delta(m) = m,
%\end{align}
%revealing $m$, which can be compared against its hash to verify the signature's validity.

%Taking Eq.~\eqref{eq:diff_sol} and grouping public information on the right we obtain,
%\begin{align}
%	h(m\soplus s) &= \Delta(m)\soplus \Delta(s),\nonumber\\
%	\mathtt{sig} &= h(m\soplus s).
%\end{align}

\section{Encryption}

For asymmetric encryption we reverse the roles of $m$ and $h(m)$. Bob wishes to send message $m$ to Alice and makes public,
\begin{align}
	\mathtt{enc}(m) &= \{\Delta(m), h(m)\}. 
\end{align}
Alice now decrypts using the message hash $h(m)$ to reveal the original message,
\begin{align}
	\Delta(s_\pi) \soplus \Delta(m) \soplus h(m) = m.
\end{align}

\subsection{Multi-sigs}

Signatures are commutative, additive and composable.
\begin{align}
	\mathtt{sig}_\pi(m) = \Delta(s_\pi) \soplus h(m),
\end{align}

\subsection{Key-establishment \& secret sharing}

Using the asymmetric encryption protocol, Alice finally communicates the verification hash,
\begin{align}
	\mathtt{key} = h(\mathtt{sk}\soplus m),
\end{align}
back to Bob, who also able to verify its validity. The verification hash now provides confirmation of a jointly prepared hash-based random number given by  the XOR-salted hash of Alice's secret key and Bob's chosen salt, which cannot be spoofed by either.

\section{Notes}

* The hash collision space translates to decoding failure.

Differentially encoded tuples are composable under bitwise XOR,
\begin{align}
	[x,\Delta(x)] \soplus [y,\Delta(y)] = [x\soplus y, \Delta(x)\soplus \Delta(y)],
\end{align}
via the commutativity of $\soplus$.

Compare above rhs,
\begin{align}
	h(x\soplus y) \soplus x \soplus y = h(x \soplus y) \soplus h(x) \soplus h(y).
\end{align}

$\pi$ known by inverting $\pi$ and multiplying the tuple elements to confirm consistency. For unknown or incorrect $\pi$ hash verification fails.

The bit permutation operator, $\pi(\cdot)$, is distribute over the bit-wise XOR operator, $\soplus$,
\begin{align}
	\pi(x)\soplus \pi(y) = \pi(x\soplus y).
\end{align}
Hence differential encoding relationships are preserved under the uniform action of $\pi$,
\begin{align}
	[x,x\soplus y] &\sim [\pi(x), \pi(x\soplus y)],
\end{align}
but are in general not preserved under non-uniform action of $\pi$,
\begin{align}
	[x,x\soplus y] \not\sim [\pi(x), x\soplus y].
\end{align}
We'll employ the shorthand,
\begin{align}
	\pi\circ[x,y] = [\pi(x),\pi(y)].,
\end{align}
to denote the uniform action of $\pi$ over a differential code.

While permutations are distributive over $\soplus$ they do not commute through hashes,
\begin{align}
	\pi(h(x)) \neq h(\pi(x)).	
\end{align}

\begin{align}
	\Delta(\pi(x\soplus y)) = h(\pi(x\soplus y)) \soplus \pi(x) \soplus \pi(y).
\end{align}

\section{From other document}

\subsubsection{Notes}

If $\Delta(x)=h(x)\soplus x$ is public information both $x$ and $h(x)$ must be private.

Decrypt $m$ with $h(m)$ requires the locking construction,
\begin{align}
	&[h(m), m\soplus h(m)]_\soplus	= [h(m), \Delta(m)]_\soplus,\nonumber\\
	&[s\soplus h(m), \Delta(s) \soplus \Delta(m)]_\soplus,\nonumber\\
	&[s\soplus h(m), \Delta(s\soplus h(m))]_\soplus \nonumber\\
	&[s\soplus h(m), \Delta(s) \soplus \Delta(m) \soplus h(s\soplus h(m)) \soplus h(m) \soplus h(s)]_\soplus,\nonumber\\
%	&[s\soplus h(m), \Delta(s) \soplus \Delta(m) \soplus  \soplus h(m) \soplus h(s)]_\soplus
\end{align}
if $\Delta(m)$ is public.


This does not unlock from known $\pi$,
\begin{align}
	[h(\pi(m)), \pi(m) \soplus h(m)]_\soplus
\end{align}

This unlocks,
\begin{align}
	[h(\pi(s \soplus m)), \Delta(s \soplus m)]_\soplus
\end{align}

%Equivalently,
%\begin{align}
%	&[h(s\soplus h(m)), \Delta(s\soplus h(m))]_\soplus \nonumber\\
%	&[s \soplus h(m), \Delta(s) \soplus \Delta(m)]_\soplus \nonumber\\
%	&[\pi(s) \soplus h(m), \Delta(s) \soplus \Delta(m)]_\soplus \to m \nonumber\\
%	&[\pi(s) \soplus \pi(h(m)), \Delta(s) \soplus \pi(\Delta(m))]_\soplus \to m \nonumber\\
%\end{align}
%unlocks for known $\Delta(\pi(s))$ (private).

Want to decrypt with,
\begin{align}
	h(\pi(s\soplus h(m)) &= \Delta(\pi(s\soplus h(m))) \nonumber\\
	&\soplus \pi(s) \soplus \pi(h(m)).
\end{align}

\begin{align}
	[h(m), \Delta(\pi(m))\soplus \Delta(\pi(s))]_\soplus
\end{align}
unlocks for known $\Delta(\pi(s))$ (private).

\begin{align}
	\Delta(\pi(m))\soplus \Delta(\pi(s))	= \Delta
\end{align}


\begin{align}
	&\mathtt{sig} = \Delta(m) = \pi(m) \soplus h(\pi(m)) \nonumber\\
	&\pi(m) = \mathtt{sig} \soplus h(\pi(m)) 
\end{align}

\subsection{Digital signatures}

Consider parties Alice and Bob where Alice wants to sign the message \mbox{$m\in \{0,1\}^n$}. Alice prepares the signature,
\begin{align}
	\mathtt{sig}(m) &= \{\pi(m), \Delta(m), h(\mathtt{sk} \soplus m)\}.
\end{align}

Bob prepares $\pi(\Delta(m))$ and knows $\pi(\Delta(\mathtt{sk}))$. We have the relationship,
\begin{align}
	\pi(\mathtt{sk} \soplus m) = \pi(\Delta(\mathtt{sk}) \soplus \Delta(m) \soplus h(m) \soplus(h(\mathtt{sk}))%  \soplus h(\mathtt{sk}) \soplus h(m)
\end{align}

The encodings,
\begin{align}
	[\mathtt{sk}, \Delta(\mathtt{sk})]_H, [h(\mathtt{sk}), \Delta(\mathtt{sk})]_\soplus \nonumber\\
	[m, \Delta(m)]_H, [h(m), \Delta(m)]_\soplus \nonumber\\
	[m \soplus \mathtt{sk} \soplus h(m) \soplus h(\mathtt{sk}), \Delta(m) \soplus \Delta(\mathtt{sk})]_\soplus
\end{align}
enable verification by hashing the first term.

The differential code,
\begin{align}
	[\mathtt{sk} \soplus m, \Delta(\mathtt{sk} \soplus m)] %\soplus h(m) \soplus h(\mathtt{sk})]
\end{align}
is verifiable given $h(\mathtt{sk} \soplus m)$, while the permuted code,
\begin{align}
	[\pi(\mathtt{sk} \soplus m), \Delta(\pi(\mathtt{sk} \soplus m))]_H 
\end{align}
is only verifiable with $h(\pi(\mathtt{sk} \soplus m))$.

\begin{align}
	&[h(\mathtt{sk} \soplus m), \Delta(\mathtt{sk} \soplus m)]_\soplus \nonumber\\
	&[h(\pi(\mathtt{sk} \soplus m)), \Delta(\pi(\mathtt{sk} \soplus m))]_\soplus
\end{align}
are both verifiable from direct multiplication.

%\begin{align}
%	&[h(\pi(\mathtt{sk} \soplus m)), \Delta(\mathtt{sk} \soplus m)]_\soplus \nonumber\\
%	&[h(\pi(\mathtt{sk} \soplus m)), h(\mathtt{sk} \soplus m)\soplus \mathtt{sk} \soplus m]_\soplus
%\end{align}
%is verifiable from direct multiplication where $\pi$ is known.



%\begin{align}
%	\pi(\Delta(\mathtt{sk} \soplus m)) &= \pi(h(\mathtt{sk} \soplus m)) \soplus \pi(\mathtt{sk}) \soplus \pi(\Delta(m)\soplus h(m)).
%\end{align}

\subsection{Blah}

Hence,
\begin{align}
	[h(\pi(\mathtt{sk} \soplus m)), \Delta(\pi(\mathtt{sk} \soplus m))]
\end{align}
affords direct verification by multiplying ($t_1\cdot t_2 = h(t_2)$). The second term is equivalent to,
\begin{align}
	t_2 &= \Delta(\pi(\mathtt{sk} \soplus m)) \nonumber\\
	&= \Delta(\pi(\mathtt{sk})) \soplus \Delta(\pi(m)) \nonumber\\
	&\soplus h(\pi(\mathtt{sk} \soplus m))
 \soplus h(\pi(\mathtt{sk})) \soplus h(\pi(m))
\end{align}

%\begin{align}
%	\pi(\Delta(\pi(x))) &= \pi(h(\pi(x))) \soplus x	
%\end{align}

Let signature be,
\begin{align}
	\mathtt{sig} &= h(\pi(\mathtt{sk} \soplus m)),\nonumber\\
\end{align}

\begin{align}
	\mathtt{ver} &= \Delta(\pi(\mathtt{sk} \soplus m)) \nonumber\\
\end{align}

\begin{align}
	[\mathtt{sig}, \mathtt{ver}]
\end{align}


\section{Blah}

\begin{align}
	\Delta(\pi(\mathtt{sk} \soplus m)) &= h(\pi(\mathtt{sk} \soplus m)) \soplus \pi(\mathtt{sk} \soplus m) \nonumber\\
	&= h(\pi(\mathtt{sk}) \soplus \pi(m)) \soplus \pi(\mathtt{sk} \soplus m). \nonumber\\
	\Delta(\pi(\mathtt{sk})) \soplus \Delta(\pi(m)) &= \pi(\mathtt{sk}) \soplus \pi(m) \nonumber\\
	&\soplus h(\pi(\mathtt{sk})) \soplus h(\pi(m)).\nonumber\\
	\Delta(\pi(\mathtt{sk} \soplus m)) &= \Delta(\pi(\mathtt{sk})) \soplus \Delta(\pi(m)) \nonumber\\
	&\soplus h(\pi(\mathtt{sk} \soplus m))
 \soplus h(\pi(\mathtt{sk})) \soplus h(\pi(m))
\end{align}

\begin{align}
	\Delta(x\soplus\pi(x)) &= h(x\soplus \pi(x)) \soplus x \soplus \pi(x).
\end{align}

\begin{align}
	\Delta(\mathtt{sk} \soplus m \soplus \pi(\mathtt{sk}\soplus m)) &= h(\mathtt{sk} \soplus m \soplus \pi(\mathtt{sk}) \soplus \pi(m)) \nonumber\\
	&\mathtt{sk} \soplus m \soplus \pi(\mathtt{sk}) \soplus \pi(m).
\end{align}

The differential permuted code,
\begin{align}
	&[\pi(\mathtt{sk} \soplus m), \Delta(\pi(\mathtt{sk} \soplus m))]
\end{align}
is verifiable from,
\begin{align}
	h(\pi(\mathtt{sk} \soplus m))
\end{align}

The differential permuted code,
\begin{align}
	&[\pi(\mathtt{sk} \soplus m), \Delta(\pi(\mathtt{sk} \soplus m))]
\end{align}
is verifiable from,
\begin{align}
	&h(\pi(\mathtt{sk} \soplus m)) \soplus \pi(\mathtt{sk} \soplus m) = bob \nonumber\\
	&\soplus h(\pi(\mathtt{sk} \soplus m)) \soplus h(\pi(\mathtt{sk})) \soplus h(\pi(m)) \nonumber\\
	&= 
\end{align} 

While,
\begin{align}
	&[\mathtt{sk} \soplus m, \Delta(\mathtt{sk} \soplus m)] \nonumber\\
	&= [\mathtt{sk} \soplus m, \Delta(\mathtt{sk}) \soplus \Delta(m) \nonumber\\
	&\soplus h(\mathtt{sk} \soplus m) \soplus h(\mathtt{sk}) \soplus h(m)],
\end{align}
is verifiable from $h(\mathtt{sk} \soplus m)$.

Bob's test passes if,
\begin{align}
	\pi(\mathtt{sk} \soplus m) &= \Delta(\pi(\mathtt{sk})) \soplus \Delta(\pi(m)) \soplus h(\pi(\mathtt{sk})) \soplus h(\pi(m))
\end{align}

Bob is not allowed to know $h(\mathtt{sk})$.

Similarly,
\begin{align}
	&[\mathtt{sk} \soplus m, \Delta(\mathtt{sk}\soplus m)] \nonumber\\
	&= [\mathtt{sk} \soplus m, h(\mathtt{sk}\soplus m) \soplus h(\mathtt{sk}) \soplus h(m)],
\end{align}
are verifiable from hashing the first term, while,
\begin{align}
	&[\pi(\mathtt{sk} \soplus m), \Delta(\mathtt{sk}\soplus m)] \nonumber\\
	&= [\pi(\mathtt{sk} \soplus m), h(\mathtt{sk}\soplus m) \soplus h(\mathtt{sk}) \soplus h(m)],
\end{align}
are verifiable by hashing the unpermuted first term. Equivalently,
\begin{align}
	&[\pi(\mathtt{sk} \soplus m), \Delta(\mathtt{sk}\soplus m)] \nonumber\\
	&[\pi(\mathtt{sk} \soplus m), \Delta(\mathtt{sk})\soplus \Delta(m) \soplus h(\mathtt{sk}\soplus m) \soplus h(\mathtt{sk}) \soplus h(m)] \nonumber\\\end{align}
is verifiable by hashing the unpermuted first term.

Using,
\begin{align}
	\Delta(\mathtt{sk}) \soplus \Delta(m) &= \Delta(\mathtt{sk} \soplus m) \soplus h(\mathtt{sk} \soplus m)	\soplus h(\mathtt{sk}) \soplus h(m),\nonumber\\
\end{align}

%We have,
%\begin{align}
%	\pi(\Delta(\mathtt{sk}\soplus m)) = \pi(\Delta(\mathtt{sk}) \soplus \Delta(m) h(\mathtt{sk}\soplus m) \soplus h(\mathtt{sk}) \soplus h(m))
%\end{align}

Ver:
\begin{align}
	\{\pi(m)\soplus \pi(\mathtt{sk}), \Delta(m)\soplus \Delta(\mathtt{sk})\} \nonumber\\
	\{\pi(m\soplus \mathtt{sk}), \Delta(m)\soplus \Delta(\mathtt{sk})\}
\end{align}

We have the relationships,
\begin{align}
	\Delta(\mathtt{sk}) \soplus \Delta(m) &= \mathtt{sk} \soplus m \soplus h(\texttt{sk}) \soplus h(m),\nonumber\\
	\Delta(\mathtt{sk} \soplus m)	 &= h(\mathtt{sk} \soplus m) \soplus \mathtt{sk} \soplus m,\nonumber\\
\end{align}
Under composition we obtain,
\begin{align}
	\Delta(\mathtt{sk} \soplus m)	 \soplus \Delta(\mathtt{sk}) \soplus \Delta(m) &= h(\mathtt{sk} \soplus m) \soplus h(\mathtt{sk}) \soplus h(m).	
\end{align}
The differential encoding,
\begin{align}
	[h(\mathtt{sk}\soplus m), \Delta(\mathtt{sk} \soplus m)],
\end{align}

Consider the permuted differential code,
\begin{align}
	[\pi(\mathtt{sk}\soplus m), \pi(\Delta(\mathtt{sk})) \soplus \pi(\Delta(m))].
\end{align}
we equivalently obtain,
\begin{align}
	[\Delta(\mathtt{sk} \soplus m) \soplus h(\mathtt{sk} \soplus m), \Delta(\mathtt{sk}) \soplus \Delta(m)].
\end{align}
%is verifiable if $\pi(\mathtt{sk} \soplus m)$ is known.

Therefore if Alice provides the signature,
\begin{align}
	\mathtt{sig}(m) = [\pi(\mathtt{sk} \soplus m), h(\mathtt{sk} \soplus m)],
\end{align}	
Bob is able to verify via,
\begin{align}
		[\mathtt{sig}(m),\Delta(\mathtt{sk}) \soplus \Delta(m)].
\end{align}


%where $\Delta(m)$ are $\Delta(\mathtt{sk})$ are known to Bob.

%which Bob is able to verify using Alice's verification hash,
%\begin{align}
%	h(\mathtt{sk}\soplus m).
%\end{align}
%
%For $n$-bit messages 

\bibliography{bibliography.bib}

\end{document}